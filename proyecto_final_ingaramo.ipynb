{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPxHT9Rq0RY2i2nsawxnC6v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eugeinga/CODER-DataScienceIII/blob/main/proyecto_final_ingaramo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DATA SCIENCE III: NLP, Deep learning y Redes Neuronales Básicas**\n"
      ],
      "metadata": {
        "id": "4EGej2tT5tME"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Portada](https://github.com/eugeinga/CODER-DataScienceII/raw/main/IMG/IMG-BannerCODER.jpg)"
      ],
      "metadata": {
        "id": "BMi28owzGtgj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Comisión:** 74560\n",
        "* **Profesor:** Ezequiel Juan Bassano\n",
        "* **Tutor:** Federico Gravina\n",
        "* **Estudiante:** [Eugenia Ingaramo](https://www.linkedin.com/in/eugeniaingaramo/)"
      ],
      "metadata": {
        "id": "uwWn4Qc15x1d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PROYECTO FINAL: Análisis de reseñas sobre tiendas online de ropa para mujer**"
      ],
      "metadata": {
        "id": "R23CcA304Dec"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"1\"></a>\n",
        "# <div style=\"padding:20px;color:yellow;margin:0;font-size:30px;font-family:Verdana;text-align:center;display:fill;border-radius:5px;background-color:#333333;overflow:hidden\"><b>CONTENIDO DEL PROYECTO </b></div>"
      ],
      "metadata": {
        "id": "pjiNlhSBn-2T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"toc\">\n",
        "  <ul>\n",
        "    <li>INTRODUCCIÓN</li>\n",
        "    <li>OBJETIVOS e HIPÓTESIS</li>\n",
        "    <li>EL SET DE DATOS</li>\n",
        "    <li>PRE-PROCESAMIENTO DE DATOS\n",
        "    <ul>\n",
        "      <li>Librerías a utilizar</li>\n",
        "      <li>Carga de Datos</li>\n",
        "      <li>Data Wrangling\n",
        "        <ul>\n",
        "          <li>Valores Duplicados</li>\n",
        "          <li>Valores Faltantes</li>\n",
        "          <li>Transformación de datos</li>\n",
        "        </ul>\n",
        "      </li>\n",
        "      <li>Limpieza de texto</li>\n",
        "      <ul>\n",
        "          <li>Normalización</li>\n",
        "          <li>Signos de Puntuación</li>\n",
        "          <li>Tokenización</li>\n",
        "          <li>Stopwords</li>\n",
        "          <li>Steming</li>\n",
        "          <li>Lematización</li>\n",
        "        </ul>\n",
        "    </ul>\n",
        "    </li>\n",
        "    <li>ANÁLISIS EXPLORATORIO DE DATOS (EDA)\n",
        "      <ul>\n",
        "        <li>Frecuencia de las palabras</li>\n",
        "        <li>Nubes de palabras y n-gramas</li>\n",
        "        <li>Análisis de Sentimientos</li>\n",
        "      </ul>          \n",
        "    <li>MODELADO\n",
        "      <ul>\n",
        "        <li>TF-IDF - Term Frequency-Inverse Document Frequency</li>\n",
        "        <li>Bag Of Words (BOW)</li>  \n",
        "      </ul>\n",
        "    <li>CONCLUSIÓN</li>\n",
        "    <li>REFERENCIAS</li>\n",
        "  </ul>\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "szp0-J9ZoJTs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"1\" href=\"#introduccion\"></a>\n",
        "# <div style=\"padding:20px;color:yellow;margin:0;font-size:30px;font-family:Verdana;text-align:center;display:fill;border-radius:5px;background-color:#333333;overflow:hidden\"><b>INTRODUCCION </b></div>"
      ],
      "metadata": {
        "id": "LPhlcsIJejhK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Datset Cover](https://github.com/eugeinga/CODER-DataScienceIII/raw/main/IMG-Indumentaria.jpg)"
      ],
      "metadata": {
        "id": "J6pay3sSBpXv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En el competitivo mundo del e-commerce de indumentaria femenina, entender las opiniones de las clientas es clave para mejorar la experiencia de compra, optimizar el catálogo de productos y aumentar la fidelización. Sin embargo, las reseñas suelen estar en formato texto no estructurado, lo que dificulta su análisis masivo.\n",
        "Este proyecto busca transformar estas reseñas en información valiosa, identificando patrones de satisfacción e insatisfacción y construyendo un modelo que permita clasificar automáticamente las opiniones como positivas o negativas."
      ],
      "metadata": {
        "id": "48SU4MbJguaY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"1\"></a>\n",
        "# <div style=\"padding:20px;color:yellow;margin:0;font-size:30px;font-family:Verdana;text-align:center;display:fill;border-radius:5px;background-color:#333333;overflow:hidden\"><b>OBJETIVO</b></div>"
      ],
      "metadata": {
        "id": "i9n9VKMRg7ZA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El presente trabajo tiene por objeto analizar y modelar reseñas de indumentaria femenina para:\n",
        "\n",
        "* Aplicar técnicas de Procesamiento de Lenguaje Natural (NLP) que permitan extraer insights relevantes.\n",
        "\n",
        "* Desarrollar un modelo de clasificación supervisado que prediga la polaridad de una reseña (positiva/negativa) a partir de su texto."
      ],
      "metadata": {
        "id": "TWxPDtfXhCqr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"1\"></a>\n",
        "# <div style=\"padding:20px;color:yellow;margin:0;font-size:30px;font-family:Verdana;text-align:center;display:fill;border-radius:5px;background-color:#333333;overflow:hidden\"><b>EL SET DE DATOS </b></div>"
      ],
      "metadata": {
        "id": "RUA-IKofnavn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **◼️ ORIGEN DE LOS DATOS**\n",
        "----\n",
        "\n",
        "**Women’s Clothing E-Commerce Reviews**, disponible públicamente en Kaggle:\n",
        "<https://www.kaggle.com/datasets/nicapotato/womens-ecommerce-clothing-reviews>\n",
        "\n",
        "Este es un conjunto de datos de comercio electrónico de ropa femenina que gira en torno a las reseñas escritas por los clientes."
      ],
      "metadata": {
        "id": "vabLk05cV-Dm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **◼️ VARIABLES**\n",
        "----\n",
        "Este conjunto de datos incluye 23.486 filas y 10 variables de características. Cada fila corresponde a una reseña de un cliente e incluye las siguientes variables:\n",
        "\n",
        "* **ID de la prenda:** variable categórica entera que hace referencia a la prenda específica que se reseña.\n",
        "* **Edad:** variable entera positiva que indica la edad del reseñador.\n",
        "* **Título:** Variable de cadena para el título de la reseña.\n",
        "* **Texto de la reseña:** Variable de cadena para el cuerpo de la reseña.\n",
        "* **Calificación:** Variable entera ordinal positiva para la puntuación del producto otorgada por el cliente, desde 1 (peor) hasta 5 (mejor).\n",
        "* **IND recomendado:** Variable binaria que indica si el cliente recomienda el producto, donde 1 significa recomendado y 0 no recomendado.\n",
        "* **Recuento de comentarios positivos:** Número entero positivo que documenta el número de otros clientes que consideraron positiva esta reseña.\n",
        "* **Nombre de la división:** Nombre categórico de la división de alto nivel del producto.\n",
        "* **Nombre del departamento:** Nombre categórico del departamento del producto.\n",
        "* **Nombre de la clase:** Nombre categórico de la clase del producto.\n",
        "\n",
        "\n",
        "Para la clasificación se crea una variable binaria objetivo \"Sentiment\":\n",
        "* 1 (Positivo) = Rating 4 o 5.\n",
        "* 0 (Negativo) = Rating 1 o 2.\n",
        "\n",
        "Se excluirán las reseñas con rating 3 (neutral)."
      ],
      "metadata": {
        "id": "0vLk_RRslv68"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"1\"></a>\n",
        "# <div style=\"padding:20px;color:yellow;margin:0;font-size:30px;font-family:Verdana;text-align:center;display:fill;border-radius:5px;background-color:#333333;overflow:hidden\"><b>PRE-PROCESAMIENTO DE DATOS </b></div>"
      ],
      "metadata": {
        "id": "678TtHrMqL3f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **◼️ LIBRERÍAS A UTILIZAR**\n",
        "----"
      ],
      "metadata": {
        "id": "VWPfh-GvWPST"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZcCNhdHM_4K_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd                                           # manejo de datos\n",
        "import numpy as np                                            # manejo de arreglos\n",
        "import missingno as msno                                      # visualización de datos faltantes\n",
        "import re                                                     # Para trabajar con expresiones regulares\n",
        "import chardet                                                # Para identificar el encoding del archivo de datos\n",
        "import requests                                               # Para salvar limitaciones de acceso a internet del entorno de ejecución\n",
        "\n",
        "import nltk                                                   # Biblioteca para procesamiento de lenguaje natural - NATURAL LANGUAGE TOOLKIT\n",
        "nltk.download('punkt')                                        # Descarga el paquete de tokenización de NLTK\n",
        "nltk.download('punkt_tab')                                    # Descarga el paquete de tokenización de NLTK\n",
        "nltk.download('stopwords')                                    # Descarga el paquete de stopwords de NLTK\n",
        "nltk.download('wordnet')                                      # Descarga el paquete de WordNet de NLTK (base de datos léxica para lematización en inglés)\n",
        "from nltk.corpus import stopwords                             # Para acceder a listas de palabras vacías (stopwords) en distintos idiomas\n",
        "from nltk.tokenize import word_tokenize                       # Desde el módulo tokenize de NLTK, se importa sólo la función word_tokenize\n",
        "from nltk.stem import PorterStemmer                           # Desde el módulo stem de NLTK, se importa sólo la función PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer                       # Desde el módulo stem de NLTK, se importa sólo la función WordNetLemmatizer\n",
        "\n",
        "from wordcloud import WordCloud                               # Para trabajar con nubes de palabras\n",
        "from textblob import TextBlob                                 # Para análisis de sentimientos\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer   # Para convertir texto en vectores/matrices de frecuencia (BOW: Bag Of Words)\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer   # Para generar frecuencias TF-IDF (frecuencia inversa de documentos) y convertir texto en una matriz numérica\n",
        "from sklearn.model_selection import train_test_split          # Para dividir los datos en entrenamiento y prueba\n",
        "from sklearn.linear_model import LogisticRegression           # Algoritmo de clasificación binaria\n",
        "from sklearn.preprocessing import StandardScaler              # Para escalar los datos y mejorar la estabilidad del entrenamiento\n",
        "\n",
        "from sklearn.metrics import classification_report             # Para calcular las métricas del modelo\n",
        "from sklearn.metrics import accuracy_score                    # Para calcular qué tan bien predice el modelo en datos nuevos (exactitud). Predicciones correctas / Total de casos.\n",
        "from sklearn.metrics import precision_score                   # Para calcular el costo de un falso positivo. Proporción de predicciones positivas que son realmente positivas.\n",
        "from sklearn.metrics import recall_score                      # Para calcular cuántos de los casos positivos reales fueron capturados por el modelo.\n",
        "from sklearn.metrics import f1_score                          # Para calcular la relación entre precisión y recall.\n",
        "from sklearn.metrics import confusion_matrix                  # Para calcular la Matriz de Confusión (Muestra los aciertos y errores del modelo organizados por clase)\n",
        "from sklearn.metrics import roc_auc_score                     # Para calcular qué tan bien el modelo separa las clases.\n",
        "\n",
        "import matplotlib.pyplot as plt                               # Para crear gráficos y visualizaciones\n",
        "import seaborn as sns                                         # Para crear gráficos y visualizaciones\n",
        "#from seaborn import lmplot\n",
        "#import matplotlib.style as style\n",
        "\n",
        "#from sklearn.preprocessing import LabelEncoder      # conversión de variables categóricas\n",
        "#from sklearn.preprocessing import StandardScaler    # escalado de datos\n",
        "#from sklearn.preprocessing import RobustScaler      # escalado de datos\n",
        "\n",
        "#import scipy.stats as stats                         # análisis estadístico\n",
        "#from scipy.stats import shapiro                     # Test estadístico de Normalidad\n",
        "\n",
        "#import statsmodels.api as sm                        # Gráfico QQ-Plot\n",
        "#from statsmodels.regression.linear_model import OLS # para análisis de multicolinealidad (VIF)\n",
        "#from statsmodels.tools.tools import add_constant    # para análisis de multicolinealidad (VIF)\n",
        "\n",
        "#from sklearn.model_selection import cross_val_score\n",
        "#from sklearn.model_selection import GridSearchCV\n",
        "#from sklearn.ensemble import RandomForestRegressor  # Random Forest\n",
        "#from sklearn.svm import SVC                         # Support Vector Machine (SVM) para Clasificación\n",
        "#from sklearn.neighbors import KNeighborsRegressor   # K-Nearest Neighbor (KNN)\n",
        "#from sklearn.pipeline import Pipeline, make_pipeline\n",
        "#from sklearn.metrics import classification_report, mean_squared_error\n",
        "#from sklearn.inspection import permutation_importance\n",
        "\n",
        "#import statsmodels.api as sm\n",
        "#from statsmodels.miscmodels.ordinal_model import OrderedModel # Regresión Logística Ordinal\n",
        "\n",
        "#sns.set_theme(style=\"whitegrid\", palette=\"pastel\") # Estilo de seaborn\n",
        "#custom_palette = {\n",
        "#    0: '#ffb482',  # Tipo de vino: RED (type=0) Color Naranja\n",
        "#    1: '#a1c9f4',  # Tipo de vino: WHITE (type=1) Color Azul\n",
        "#    'red': '#ffb482',  # Tipo de vino: RED (type=0) Color Naranja\n",
        "#    'white': '#a1c9f4'  # Tipo de vino: WHITE (type=1) Color Azul\n",
        "#}\n",
        "\n",
        "#sns.color_palette(\"pastel\")\n",
        "#sns.color_palette(\"pastel\").as_hex()\n",
        "#sns.color_palette(palette='pastel', as_cmap=True)\n",
        "\n",
        "import warnings                                               # Para tratamiento de errores/alertas\n",
        "#warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **◼️ CARGA DE DATOS**\n",
        "----\n",
        "\n",
        "Como primera medida, se detecta el encoding del archivo a utilizar con la librería \"chardet\""
      ],
      "metadata": {
        "id": "6IMIS-uEiM5Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://raw.githubusercontent.com/eugeinga/CODER-DataScienceIII/main/Womens%20Clothing%20E-Commerce%20Reviews.csv\" # Descarga el contenido del archivo desde la URL\n",
        "response = requests.get(url)\n",
        "result = chardet.detect(response.content[:10000])                                                                         # Detecta el encoding usando chardet\n",
        "print(result)"
      ],
      "metadata": {
        "id": "Z30fgcY9AcFs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aunque chardet detectó 'ascii' con alta confianza, ese encoding no es suficiente para leer correctamente el archivo, posiblemente caracteres especiales (como acentos) que no están en el conjunto ASCII. Por lo tanto, haré uso de ISO-8859-1."
      ],
      "metadata": {
        "id": "ce5mjpaXC1l1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lectura del dataset con encoding='ISO-8859-1' para evitar errores de lectura cuando el archivo contiene caracteres especiales que no están en ASCII o UTF-8.\n",
        "\n",
        "url=\"https://raw.githubusercontent.com/eugeinga/CODER-DataScienceIII/refs/heads/main/Womens%20Clothing%20E-Commerce%20Reviews.csv\"\n",
        "dfReviews=pd.read_csv(url,sep=',',header=0, encoding='ISO-8859-1')\n",
        "dfReviews.head()"
      ],
      "metadata": {
        "id": "w0ux86UfDkJD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **◼️ DATA WRANGLING**\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "52LXCUzF3VDW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El **Data Wrangling** consiste en limpiar, transformar y estructurar los datos para que sean más utilizables y valiosos. Este proceso es esencial porque los datos en su forma original a menudo están desordenados, incompletos o contienen errores que pueden afectar la calidad del análisis.\n",
        "\n",
        "Como parte de esta etapa se procederá a:\n",
        "- Identificar valores duplicados\n",
        "- Identificar valores faltantes\n",
        "- Transformar datos (normalización, estandarización, etc.).\n",
        "\n",
        "En este caso se trabaja con un único dataset por lo que no será necesario combinar/concatenar ficheros."
      ],
      "metadata": {
        "id": "WwPtH_Lc6I0w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Información de resumen del dataset\n",
        "dfReviews.info()"
      ],
      "metadata": {
        "id": "swUMxE7mEatR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El dataset bajo estudio cuenta con 23486 filas y 10 columnas de las cuales 9 corresponden a variables independientes a analizar y 1 a la variable dependiente u objetivo."
      ],
      "metadata": {
        "id": "_8XdPQc_qdEH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cardinalidad de las variables\n",
        "\n",
        "cardinalidad = pd.DataFrame({'Cantidad' : dfReviews.nunique(), 'Porcentaje' : (dfReviews.nunique()) / (dfReviews.shape[0]) * (100)}).round(2)\n",
        "cardinalidad"
      ],
      "metadata": {
        "id": "TxU-xewjhH1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **◾ VALORES DUPLICADOS**\n",
        "\n",
        "##### Se identifican y remueven de los registros duplicados"
      ],
      "metadata": {
        "id": "N3J0mGR_LTkO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Dimensiones del dataset original: \", dfReviews.shape)\n",
        "dfReviews.duplicated().value_counts()\n",
        "dfReviews.drop_duplicates(inplace=True)\n",
        "print(\"Dimensiones del dataset sin filas duplicadas: \", dfReviews.shape)"
      ],
      "metadata": {
        "id": "6xnagbRzrBow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El dataset no tiene registros duplicadas que eliminar."
      ],
      "metadata": {
        "id": "U24VOaI1rI0E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **◾ VALORES FALTANTES**\n",
        "\n",
        "Se identifican los valores nulos en cada una de las columnas del dataset."
      ],
      "metadata": {
        "id": "NkPHWMfUJ_f4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Contabilizo los datos nulos/faltantes por columna.\n",
        "\n",
        "pd.DataFrame({'Cant.NAN' : dfReviews.isna().sum(), '%NAN' : dfReviews.isna().sum() / len(dfReviews) * (100)}).round(2)"
      ],
      "metadata": {
        "id": "Uri8fSIReBF5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "msno.matrix(dfReviews)"
      ],
      "metadata": {
        "id": "MgXKUH8bZWsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se eliminan los registros donde el campo \"Review Text\" sea nulo dado que no aportan valor al análisis a realizar."
      ],
      "metadata": {
        "id": "LTaemB_BZS1q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Dimensiones del dataset antes de la remoción de valores faltantes: \", dfReviews.shape)\n",
        "dfReviews.dropna(subset=['Review Text'], inplace=True)\n",
        "print(\"Dimensiones del dataset sin valores faltantes en 'Review Text': \", dfReviews.shape)"
      ],
      "metadata": {
        "id": "YO6sVW5HZkom"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se determina la longitud mínima, máxima y promedio de la variable \"Review Text\":"
      ],
      "metadata": {
        "id": "TIWltp7G9Q8S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dfReviews[\"review_length\"] = dfReviews[\"Review Text\"].apply(len)\n",
        "#dfReviews[\"review_length\"] = dfReviews[\"Review Text\"].fillna(\"\").apply(len)\n",
        "\n",
        "max_length = dfReviews[\"review_length\"].max()\n",
        "min_length = dfReviews[\"review_length\"].min()\n",
        "avg_length = dfReviews[\"review_length\"].mean()\n",
        "\n",
        "print(f\"Longitud máxima de reseñas: {max_length}\")\n",
        "print(f\"Longitud mínima de reseñas: {min_length}\")\n",
        "print(f\"Longitud promedio de reseñas: {avg_length:.2f}\")"
      ],
      "metadata": {
        "id": "27rvZXU89X9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **◾ TRANSFORMACIÓN DE DATOS**\n",
        "\n",
        "Como parte del proceso de transformación de datos se crea la variable binaria \"Sentiment\" a partir de la variable \"Rating\" asumiendo ratings 4 y 5 como positivos, 1 y 2 como negativos, descartando ratings 3."
      ],
      "metadata": {
        "id": "fJ6LxzV82Ji4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = dfReviews[dfReviews['Rating'] != 3].copy()\n",
        "df['Sentiment'] = np.where(df['Rating'] >= 4, \"Positivo\", \"Negativo\")\n",
        "df['Sentiment'].value_counts(normalize=True)"
      ],
      "metadata": {
        "id": "TrFD_PAH26At"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **◼️ LIMPIEZA DEL TEXTO**\n"
      ],
      "metadata": {
        "id": "izIMQm7ELXQi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **◾ NORMALIZACIÓN**\n",
        "\n",
        "Se **normalizan** los valores pasando todo el texto a minúscula:"
      ],
      "metadata": {
        "id": "Kh_SddD-3n5f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Review_lower'] = df['Review Text'].apply(lambda text: text.lower())"
      ],
      "metadata": {
        "id": "cA5FzIa03zZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **◾ SIGNOS DE PUNTUACIÓN**\n",
        "\n",
        "Se eliminan **signos de puntuación**:"
      ],
      "metadata": {
        "id": "yIYnacAF48Bd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_punctuation(text):\n",
        "    return re.sub(r'[^a-zA-Z0-9\\s]', '', text)                          # Expresión regular para reemplazar cualquier signo de puntuación o símbolo no alfanumérico\n",
        "\n",
        "df['Review_puntuacion'] = df['Review_lower'].apply(remove_punctuation)  # Aplicar la función a la columna 'review_lower'"
      ],
      "metadata": {
        "id": "4lzTfpX_469d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **◾ TOKENIZACIÓN**\n",
        "\n",
        "Se **tokenizan** los valores de la columna \"Review Text\" para dividir el texto en unidades pequeñas (tokens) a fin de poder trabajar con cada palabra por separado (contar frecuencias, aplicar modelos, buscar significados, etc.)\n"
      ],
      "metadata": {
        "id": "yfgrO54K7F4W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Review_tokenizado'] = df['Review_puntuacion'].apply(word_tokenize)"
      ],
      "metadata": {
        "id": "_JLQKQsJ7HKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **◾ STOPWORDS**\n",
        "\n",
        "Se remueven **stopwords**, aquellas  palabras vacías que no aportan un valor significativo al análisis del texto (ej.: artículos, preposiciones, conjunciones y otros términos comunes que suelen ser irrelevantes para tareas de procesamiento de texto) y así mejorar la precisión en el análisis de sentimientos, clasificación de texto y búsqueda de información."
      ],
      "metadata": {
        "id": "Q-DQ23Ne_VTl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords_eng = stopwords.words('english')    # Para obtener el listado de stopwords en inglés dado que las reseñas están en ese idioma\n",
        "print(stopwords_eng[:20])                     # Se muestran las primeras 20 stopwords"
      ],
      "metadata": {
        "id": "6-OMYFi2_hJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#stop_words = set(stopwords.words('english'))  # Se crea una lista de stopwords en inglés usando NLTK\n",
        "stop_words = list(stopwords.words('english'))  # Se crea una lista de stopwords en inglés usando NLTK\n",
        "\n",
        "# Se define una función lamda para eliminar stopwords en cada fila de la columna 'Review_tokenizado'\n",
        "df['Review_tokenizado_sin_stopwords'] = df['Review_tokenizado'].apply(lambda tokens: [word for word in tokens if word not in stop_words])"
      ],
      "metadata": {
        "id": "-Cvcz7VLBKXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A fin de reducir la variabilidad de las palabras y facilitando el análisis del texto se procede a realizar el steming y lematización de las palabras del campo \"Rreview Text\""
      ],
      "metadata": {
        "id": "BtLbJOSHGBan"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **◾ STEMMING**\n",
        "\n",
        "Se realiza el **stemming** de las palabras para reducirlas a su raíz o forma base eliminando los sufijos de cada palabra."
      ],
      "metadata": {
        "id": "k-cMptPDHj0Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = PorterStemmer()   # Se inicializa el stemmer\n",
        "df['Review_stemming'] = df['Review_tokenizado_sin_stopwords'].apply(lambda tokens: [stemmer.stem(token) for token in tokens])  # Se aplica stemming a la columna 'Review_tokenizado_sin_stopwords'"
      ],
      "metadata": {
        "id": "pIUwtqFLGCfJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **◾ LEMATIZACIÓN**\n",
        "\n",
        "Se realiza la **lematización** de las palabras a fin de reducirlas a su lema (forma base), manteniendo el significado gramatical correcto de las palabras."
      ],
      "metadata": {
        "id": "C9g_uAc2IC19"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()  # Se inicializa el lematizador\n",
        "df['Review_lematizacion'] = df['Review_tokenizado_sin_stopwords'].apply(lambda tokens: [lemmatizer.lemmatize(token) for token in tokens]) # Se aplica la lematización a la columna 'Review_tokenizado_sin_stopwords'"
      ],
      "metadata": {
        "id": "5r4szrFNIRxP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se previsualizan las columnas generadas como parte del proceso de limpieza del texto:"
      ],
      "metadata": {
        "id": "IXJUHiArKFXe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_colwidth', None) # Para configurar pandas para mostrar el contenido completo de las columnas\n",
        "df[[\"Review Text\", \"Review_lower\", \"Review_puntuacion\", \"Review_tokenizado\", \"Review_tokenizado_sin_stopwords\", \"Review_stemming\", \"Review_lematizacion\"]].head(5)"
      ],
      "metadata": {
        "id": "l1awNM417yyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.reset_option('display.max_colwidth')     # Restaura la configuración predeterminada de pandas para el ancho de las columnas"
      ],
      "metadata": {
        "id": "8pbvG0p9KL4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"1\"></a>\n",
        "# <div style=\"padding:20px;color:yellow;margin:0;font-size:30px;font-family:Verdana;text-align:center;display:fill;border-radius:5px;background-color:#333333;overflow:hidden\"><b>ANÁLISIS EXPLORATORIO DE DATOS </b></div>"
      ],
      "metadata": {
        "id": "Q17TVK9uH4qm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se realiza un **Análisis Exploratorio de Datos** específico para NLP.\n",
        "\n",
        "Como parte de esta etapa se procederá a:\n",
        "- Analizar la frecuencia de las palabras y n-gramas.\n",
        "- Generar nubes de palabras.\n",
        "- Identificar la distribución de longitudes por clase.\n",
        "- Identificar palabras distintivas en cada clase."
      ],
      "metadata": {
        "id": "7t2NIXdE05UY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **◼️ FRECUENCIA DE PALABRAS**\n",
        "----"
      ],
      "metadata": {
        "id": "ccifFr5Uwpim"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se obtiene el listado de las palabras con mayor frecuencia:"
      ],
      "metadata": {
        "id": "vkWRahIlPmvg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "tokens_lematizados = [token for tokens_list in df['Review_lematizacion'] for token in tokens_list]  # Se unen todos los tokens lematizados en una sola lista\n",
        "frecuencia_palabras_lematizadas = Counter(tokens_lematizados)                                       # Se contabiliza la frecuencia de aparición de cada palabra\n",
        "frecuencia_palabras_lematizadas.most_common(20)                                                     # Se muestran las 20 palabras más frecuentes"
      ],
      "metadata": {
        "id": "-9_XplqOPpz6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se grafica la distribución de frecuencia de las palabras más frecuentes para las palabras Lematizadas y las Originales"
      ],
      "metadata": {
        "id": "iUcejv73SZPt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(1, 2, figsize=(16, 6))  # 1 fila, 2 columnas\n",
        "\n",
        "tokens_sin_normalizar = [token for review in df['Review Text'] for token in review.split()]   # Tokenización sin normalización previa (sin pasar a minúsculas, sin quitar puntuación)\n",
        "frecuencia_sin_normalizar = Counter(tokens_sin_normalizar)                                    # Se cuenta la frecuencia de cada palabra\n",
        "palabras_sin_norm, frecuencias_sin_norm = zip(*frecuencia_sin_normalizar.most_common(20))     # Se obtienen las 15 palabras más comunes y sus frecuencias\n",
        "# Gráfica de tokenización sin normalización previa (derecha)\n",
        "axs[0].bar(palabras_sin_norm, frecuencias_sin_norm, color='red')\n",
        "axs[0].set_title('Top 15 Palabras Sin Normalizar')\n",
        "axs[0].set_xlabel('Palabras')\n",
        "axs[0].set_ylabel('Frecuencia')\n",
        "axs[0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "palabras_lem, frecuencias_lem = zip(*frecuencia_palabras_lematizadas.most_common(15)) # Se obtienen las 15 palabras más comunes y sus frecuencias\n",
        "# Gráfica de tokenización sobre el texto lematizado (izquierda)\n",
        "axs[1].bar(palabras_lem, frecuencias_lem, color='green')\n",
        "axs[1].set_title('Top 15 Palabras Lematizadas')\n",
        "axs[1].set_xlabel('Palabras')\n",
        "axs[1].set_ylabel('Frecuencia')\n",
        "axs[1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "\n",
        "plt.tight_layout()  # Ajusta diseño para evitar superposición\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Td5rRsa9R2Lv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **◼️ NUBE DE PALABRAS Y N-GRAMAS**\n",
        "----"
      ],
      "metadata": {
        "id": "ZpIPfnT-I9Xc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se crean subplots de 1 fila, 2 columnas\n",
        "fig, axs = plt.subplots(1, 2, figsize=(18, 6))\n",
        "\n",
        "text_original = ' '.join(df['Review Text'].fillna('').astype(str))\n",
        "wordcloud_original = WordCloud(width=600, height=300, background_color='white').generate(text_original)                             # Se crea la nube de palabras con el texto original\n",
        "# Se grafica la nube de palabras original\n",
        "axs[0].imshow(wordcloud_original, interpolation='bilinear')\n",
        "axs[0].set_title('Nube de Palabras - Texto Original')\n",
        "#axs[0].axis('off')\n",
        "for spine in axs[0].spines.values():\n",
        "    spine.set_edgecolor('gray')\n",
        "    spine.set_linewidth(2)\n",
        "\n",
        "text_lematizado = ' '.join(df['Review_lematizacion'].fillna('').astype(str))\n",
        "wordcloud_lematizado = WordCloud(width=600, height=300, background_color='white', stopwords=stop_words).generate(text_lematizado)   # Se crea la nube de palabras con el texto lematizado sin stopwords\n",
        "# Se grafica la nube de palabras lematizadas\n",
        "axs[1].imshow(wordcloud_lematizado, interpolation='bilinear')\n",
        "axs[1].set_title('Nube de Palabras - Texto Lematizado')\n",
        "#axs[1].axis('off')\n",
        "for spine in axs[1].spines.values():\n",
        "    spine.set_edgecolor('gray')\n",
        "    spine.set_linewidth(2)\n",
        "\n",
        "plt.subplots_adjust(wspace=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tiCY9pk4SZXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se agregan algunas palabras a las stopwords para limpiar la nube de palabras y se vuelve a graficar."
      ],
      "metadata": {
        "id": "Z2wOIFuSY0cy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words.extend(['wear','would','one', 'dress', 'pant', 'skit', 'shirt', 'jacket', 'jean', 'sweater', 'legging', 'im']) # Agrega algunas palabras a las stopwords"
      ],
      "metadata": {
        "id": "Tv51RlrdQghJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_lematizado = ' '.join(df['Review_lematizacion'].fillna('').astype(str))  # Se crea una nueva wordcloud con el texto lematizado removiendo stopwords\n",
        "wordcloud = WordCloud(width=800, height=400, background_color='white', stopwords=stop_words).generate(text_lematizado)\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "spine.set_edgecolor('gray')\n",
        "spine.set_linewidth(2)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WZW8dVfwRU2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se generan nubes de palabras distintas según sea el sentimiento (Sentiment), positivo o negativo."
      ],
      "metadata": {
        "id": "IxLd1bkjamrs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se crean subplots de 1 fila, 2 columnas\n",
        "fig, axs = plt.subplots(1, 2, figsize=(18, 6))\n",
        "\n",
        "df['Review_lematizacion'] = df['Review_lematizacion'].apply(lambda x: ' '.join(x) if isinstance(x, list) else x)\n",
        "\n",
        "# Se grafica la nube de palabras con sentimientos positivos\n",
        "df_positivo = df[df['Sentiment'] == 'Positivo']               # Se filtran las filas con sentimiento positivo del DataFrame\n",
        "text_positivo = ' '.join(df_positivo['Review_lematizacion'])  # Se crea una nueva wordcloud con el texto lematizado\n",
        "wordcloud_positivo = WordCloud(width=800, height=400, background_color='white',stopwords=stop_words).generate(text_positivo)\n",
        "axs[0].imshow(wordcloud_positivo, interpolation='bilinear')\n",
        "axs[0].set_title('Nube de Palabras - Texto Positivo')\n",
        "for spine in axs[0].spines.values():\n",
        "    spine.set_edgecolor('gray')\n",
        "    spine.set_linewidth(2)\n",
        "\n",
        "# Se grafica la nube de palabras con sentimientos negativos\n",
        "df_negativo = df[df['Sentiment'] == 'Negativo']               # Se filtran las filas con sentimiento negativo del DataFrame\n",
        "text_negativo = ' '.join(df_negativo['Review_lematizacion'])  # Se crea una nueva wordcloud con el texto lematizado\n",
        "wordcloud_negativo = WordCloud(width=800, height=400, background_color='white',stopwords=stop_words).generate(text_negativo)\n",
        "axs[1].imshow(wordcloud_negativo, interpolation='bilinear')\n",
        "axs[1].set_title('Nube de Palabras - Texto Negativo')\n",
        "#axs[1].axis('off')\n",
        "for spine in axs[1].spines.values():\n",
        "    spine.set_edgecolor('gray')\n",
        "    spine.set_linewidth(2)\n",
        "\n",
        "plt.subplots_adjust(wspace=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "USpppQaYawZb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BAG OF WORDS (BOW)**\n",
        "\n",
        "A continuación se crean nubes de palabras en contexto positivo y negativo con n-gramas para captar contexto y matices que no se verían con palabras individuales.\n",
        "\n",
        "Para esto se utiliza una instancia de CountVectorizer (que convierte una colección de textos en una matriz de recuentos de términos) y luego ajustamos esta instancia (mediante fit_transform) al texto de cada reseña. Esto construye el vocabulario y transforma las reseñas en una matriz BoW (freqs)."
      ],
      "metadata": {
        "id": "Qi5XcMiZxL6y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Review_lematizacion'] = df['Review_lematizacion'].apply(lambda x: ' '.join(x) if isinstance(x, list) else x)  #Para convertir listas en strings si es necesario\n",
        "\n",
        "# Función para generar n-gramas\n",
        "def generate_ngrams(texts, n=3):\n",
        "    vectorizer = CountVectorizer(ngram_range=(n, n), stop_words=stop_words)           # Se crea el CountVectorizer con las stop_words definidas\n",
        "    X = vectorizer.fit_transform(texts)                                               # Se transforma el texto en n-gramas\n",
        "    freqs = dict(zip(vectorizer.get_feature_names_out(), X.sum(axis=0).tolist()[0]))  # Se crea el diccionario con los n-gramas y sus frecuencias\n",
        "    return freqs                                                                      # Se devuelve la matriz BOW (el diccionario con los n-gramas y sus frecuencias)\n",
        "\n",
        "# Crear subplots\n",
        "fig, axs = plt.subplots(1, 2, figsize=(18, 6))\n",
        "\n",
        "# Nube de n-gramas para textos positivos\n",
        "ngrams_positivo = generate_ngrams(df[df['Sentiment'] == 'Positivo']['Review_lematizacion'], n=3)\n",
        "wordcloud_positivo = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(ngrams_positivo)\n",
        "axs[0].imshow(wordcloud_positivo, interpolation='bilinear')\n",
        "axs[0].set_title('Nube de n-gramas - Texto Positivo')\n",
        "\n",
        "# Nube de n-gramas para textos negativos\n",
        "ngrams_negativo = generate_ngrams(df[df['Sentiment'] == 'Negativo']['Review_lematizacion'], n=3)\n",
        "wordcloud_negativo = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(ngrams_negativo)\n",
        "axs[1].imshow(wordcloud_negativo, interpolation='bilinear')\n",
        "axs[1].set_title('Nube de n-gramas - Texto Negativo')\n",
        "\n",
        "# Estética\n",
        "for ax in axs:\n",
        "    for spine in ax.spines.values():\n",
        "        spine.set_edgecolor('gray')\n",
        "        spine.set_linewidth(2)\n",
        "\n",
        "plt.subplots_adjust(wspace=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "atMqfKWvuWr_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "💡 Las reseñas positivas están centradas en experiencias satisfactorias y elogios. No obstante, y como era de esperar, en las reseñas negativas hay una clara expresión de decepción (\"really wanted like\", \"sadly going back\") y se perciben problemas de expectativa vs. realidad (\"look nothing like\", \"made look like\")."
      ],
      "metadata": {
        "id": "4a_4RBIhx2hy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **◼️ ANÁLISIS DE SENTIMIENTOS**\n",
        "----\n",
        "\n",
        "Se evaluan las reseñas en cuanto a su polaridad y su subjetividad:\n",
        "* La polaridad mide cuán positivo o negativo es el texto, en un rango de -1 (muy negativo) a 1 (muy positivo).\n",
        "* La subjetividad mide cuánto del texto es opinión (1) versus hecho (0)."
      ],
      "metadata": {
        "id": "cJcpNQ3wKgGs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se crea una columna con objetos TextBlob sobre la que se hará el análisis de sentimiento\n",
        "df['Blob'] = df['Review Text'].apply(TextBlob)\n",
        "\n",
        "# Se extraen la polaridad y subjetividad del sentimiento\n",
        "df['Sentiment_Polarity'] = df['Blob'].apply(lambda blob: blob.sentiment.polarity)\n",
        "df['Sentiment_Subjectivity'] = df['Blob'].apply(lambda blob: blob.sentiment.subjectivity)\n",
        "df[['Review Text', 'Sentiment_Polarity', 'Sentiment_Subjectivity']].head(10)"
      ],
      "metadata": {
        "id": "8l11PXYIhf0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_stats = df.groupby('Sentiment')[['Sentiment_Polarity', 'Sentiment_Subjectivity']].mean()  # Se agrupa por sentimiento y calculan promedios\n",
        "\n",
        "print(\"Promedio de polaridad y subjetividad por tipo de sentimiento:\")\n",
        "print(sentiment_stats)"
      ],
      "metadata": {
        "id": "jtgGUnn7l2At"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "💡 Los textos clasificados como positivos tienen una **polaridad** levemente mayor que los negativos. No obstante, los textos negativos no son extremadamente negativos (0.108), lo que podría indicar que las reseñas negativas, aunque críticas, no necesariamente usan lenguaje extremadamente negativo\n",
        "\n",
        "Ambos tipos de reseñas tienen niveles similares de **subjetividad**, aunque las positivas son ligeramente más subjetivas. Esto sugiere que los usuarios tienden a expresar más emociones o juicios personales cuando están satisfechos."
      ],
      "metadata": {
        "id": "yGmV3tT8p57z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"1\"></a>\n",
        "# <div style=\"padding:20px;color:yellow;margin:0;font-size:30px;font-family:Verdana;text-align:center;display:fill;border-radius:5px;background-color:#333333;overflow:hidden\"><b>MODELADO </b></div>"
      ],
      "metadata": {
        "id": "BqnZsIruleJ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **◼️ TF-IDF - Term Frequency-Inverse Document Frequency**\n",
        "----\n",
        "\n",
        "Para entender qué palabras tienen mayor peso dentro de las reseñas, se aplicó la técnica TF-IDF. Esta herramienta permite identificar qué términos son más representativos en los textos, destacando aquellos que aparecen con frecuencia en una reseña pero no en todas.\n",
        "\n",
        "En este trabajo, se utilizó el vectorizador TF-IDF para transformar los textos en vectores numéricos, lo que facilita su análisis y comparación. Se aplicó por separado a los textos con sentimiento positivo y negativo, lo que permitió observar qué palabras son más relevantes en cada grupo. Este enfoque ayuda a detectar patrones lingüísticos asociados a cada tipo de experiencia del usuario."
      ],
      "metadata": {
        "id": "7bloF9ja59bC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuación se realiza un **modelo de clasificación** para predecir la valoración (positiva o negativa) de un cliente a partir de una reseña, usando **TF-IDF** para transformar el texto y **Regresión Logística** como algoritmo de aprendizaje.\n",
        "\n",
        "Se considera la variable \"Review Text\" como variable independiente sobre la cual se harán las predicciones del \"Rating\"."
      ],
      "metadata": {
        "id": "1o6_uYvNdYnU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Entrenamiento del Modelo con el dataset original**\n",
        "\n",
        "Se toma el set de datos original con Ratings del 1 al 5 (multiclase)."
      ],
      "metadata": {
        "id": "Q9ndrTmPoqr1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(dfReviews['Review Text'], dfReviews['Rating'], test_size=0.2, random_state=42)  # Se dividen los datos en conjuntos de entrenamiento y prueba\n",
        "\n",
        "# Vectorización TF-IDF\n",
        "vectorizador_tfidf = TfidfVectorizer(max_features=5000)     # Se crea un vectorizador TF-IDF (el objeto del modelo o herramienta a usar)\n",
        "X_train_tfidf = vectorizador_tfidf.fit_transform(X_train)   # Se ajustan los datos de entrenamiento\n",
        "X_test_tfidf = vectorizador_tfidf.transform(X_test)         # Se transforman los datos de prueba\n",
        "\n",
        "# Escalado de los datos (para mejorar la estabilidad del entrenamiento)\n",
        "#scaler = StandardScaler(with_mean=False)\n",
        "#X_train_scaled = scaler.fit_transform(X_train_tfidf)\n",
        "#X_test_scaled = scaler.transform(X_test_tfidf)\n",
        "\n",
        "# Modelo de regresión logística\n",
        "model = LogisticRegression(max_iter=1000)                 # Se instancia el modelo\n",
        "model.fit(X_train_tfidf, y_train)                         # Se entrena el modelo (aprende) a partir de los datos de entrenamiento\n",
        "y_pred = model.predict(X_test_tfidf)                      # Se hacen  predicciones en el conjunto de prueba\n",
        "#y_pred = model.predict(X_test_scaled)                     # Se hacen  predicciones en el conjunto de prueba escalado\n",
        "\n",
        "# Mostrar predicciones\n",
        "print(\"Predicciones del modelo sobre el conjunto de prueba:\")\n",
        "print(y_pred)"
      ],
      "metadata": {
        "id": "7uwHmFmRhCXb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluación del Modelo**\n",
        "\n",
        "A continuación se evalúa el modelo a partir distintas métricas:\n",
        "\n",
        "* **Accuracy:** Indica qué tan bien predice el modelo en datos nuevos (exactitud). Mide el porcentaje total de predicciones correctas sobre el total de casos. Es una medida global del desempeño.\n",
        "* **Precision:** Indica qué proporción de las predicciones positivas realizadas por el modelo son realmente positivas. Cuántos falsos positivos se está evitando.\n",
        "* **Recall:** Indica cuántos de los casos positivos reales fueron capturados por el modelo. Cuántos verdaderos positivos se está capturando.\n",
        "* **f1 Score:** Calcula el promedio armónico entre precisión y recall. Un buen balance si ambas cosas son importantes. Es útil cuando hay cierto desequilibrio entre clases.\n",
        "* **ROC AUC SCORE:** evalúa qué tan bien el modelo separa las clases. Un valor cercano a 1 indica una excelente discriminación entre \"positivo\" y \"negativo\".\n"
      ],
      "metadata": {
        "id": "PML9Pb84ot9q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se calculan las métricas del Modelo\n",
        "accuracy_tfidf_M = accuracy_score(y_test, y_pred)\n",
        "precision_tfidf_M = precision_score(y_test, y_pred, average='weighted')  # Calcula la métrica multiclase con average='weighted'\n",
        "recall_tfidf_M = recall_score(y_test, y_pred, average='weighted') # Calcula la métrica multiclase con average='weighted'\n",
        "f1_tfidf_M = f1_score(y_test, y_pred, average='weighted') # Calcula la métrica multiclase con average='weighted'\n",
        "y_proba_tfidf_M = model.predict_proba(X_test_tfidf)\n",
        "#y_proba_tfidf_M = model.predict_proba(X_test_scaled)\n",
        "roc_auc_tfidf_M = roc_auc_score(y_test, y_proba_tfidf_M, multi_class='ovr', average='weighted') # Calcula la métrica multiclase con average='weighted'\n",
        "\n",
        "\n",
        "# Se crea un diccionario para almacenar todas las métricas\n",
        "metricas_modelos = {}\n",
        "\n",
        "# Almaceno las métricas del modelo\n",
        "metricas_modelos['RL_TFIDF_Multiclase'] = {\n",
        "    'Accuracy': accuracy_tfidf_M,\n",
        "    'Precision': precision_tfidf_M,\n",
        "    'Recall': recall_tfidf_M,\n",
        "    'F1 Score': f1_tfidf_M,\n",
        "    'ROC AUC': roc_auc_tfidf_M\n",
        "}\n",
        "\n",
        "print(\"Métricas del Modelo con TF-IDF multiclase\")\n",
        "print(f\"- Accuracy: {accuracy_tfidf_M:.3f}\")\n",
        "print(f\"- Precisión: {precision_tfidf_M:.3f}\")\n",
        "print(f\"- Recall: {recall_tfidf_M:.3f}\")\n",
        "print(f\"- F1 Score: {f1_tfidf_M:.3f}\")\n",
        "print(f\"- ROC AUC Score: {roc_auc_tfidf_M:.3f}\")\n",
        "\n",
        "# Reporte por clase\n",
        "print(\"\\n\\nReporte de Clasificación por Clase:\\n\")\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "PGZcsIl2okPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "💡 De las métricas obtenidas podemos decir que:\n",
        "* El modelo clasifica correctamente el 65.1% de los casos, lo cual indica un rendimiento aceptable considerando que se trata de una clasificación multiclase (ratings del 1 al 5).\n",
        "* En promedio, cuando el modelo predice una clase, acierta el 60.8% de las veces. Esto sugiere que hay cierto nivel de confusión entre clases, quizás en las más cercanas (por ejemplo, entre 3 y 4).\n",
        "* El modelo logra recuperar el 65.1% de los casos reales, lo que indica que está dejando algunos casos sin detectar.\n",
        "* El equilibrio entre precisión y recall es razonable, aunque hay margen para mejorar la consistencia del modelo.\n",
        "* El ROC AUC Score es relativamente alto, lo que indica que el modelo tiene buena capacidad para distinguir entre clases, especialmente entre las más extremas (ratings bajos vs. altos)."
      ],
      "metadata": {
        "id": "7UIxDT8osSVs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel('Predicción')\n",
        "plt.ylabel('Valor Real')\n",
        "plt.title('Matriz de Confusión')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "a6ostPUpphCx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "💡 La Matriz de Confusión indica que:\n",
        "* La clase 5 (rating más alto) tiene la mayor cantidad de aciertos (2313), lo que sugiere que el modelo identifica bien las reseñas muy positivas.\n",
        "* La clase 3 muestra una dispersión significativa, con muchos casos clasificados como 4 (561), lo que indica que el modelo tiene dificultades para distinguir entre reseñas neutras y ligeramente positivas.\n",
        "* Las clases 1 y 2 tienen menos aciertos y más confusión entre sí y con clases superiores, lo que podría deberse a menor cantidad de ejemplos o menor diferenciación lingüística."
      ],
      "metadata": {
        "id": "vdkhC0vZt4N-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Entrenamiento del Modelo con el dataset de clasificación binaria (positiva/negativa)**"
      ],
      "metadata": {
        "id": "CksmIbIj2I81"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['SentimentValue'] = np.where(df['Sentiment'] == \"Positivo\", 1, 0)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['Review Text'], df['SentimentValue'], test_size=0.2, random_state=42)  # Se dividen los datos en conjuntos de entrenamiento y prueba\n",
        "\n",
        "# Vectorización TF-IDF\n",
        "vectorizador_tfidf = TfidfVectorizer(max_features=5000)     # Se crea un vectorizador TF-IDF (el objeto del modelo o herramienta a usar)\n",
        "X_train_tfidf = vectorizador_tfidf.fit_transform(X_train)   # Se ajustan los datos de entrenamiento\n",
        "X_test_tfidf = vectorizador_tfidf.transform(X_test)         # Se transforman los datos de prueba\n",
        "\n",
        "# Escalado de los datos (para mejorar la estabilidad del entrenamiento)\n",
        "#scaler = StandardScaler(with_mean=False)\n",
        "#X_train_scaled = scaler.fit_transform(X_train_tfidf)\n",
        "#X_test_scaled = scaler.transform(X_test_tfidf)\n",
        "\n",
        "# Modelo de regresión logística\n",
        "model = LogisticRegression(max_iter=1000)                 # Se instancia el modelo\n",
        "model.fit(X_train_tfidf, y_train)                         # Se entrena el modelo (aprende) a partir de los datos de entrenamiento\n",
        "y_pred = model.predict(X_test_tfidf)                      # Se hacen  predicciones en el conjunto de prueba\n",
        "#y_pred = model.predict(X_test_scaled)                     # Se hacen  predicciones en el conjunto de prueba escalado\n",
        "\n",
        "# Mostrar predicciones\n",
        "print(\"Predicciones del modelo sobre el conjunto de prueba:\")\n",
        "print(y_pred)"
      ],
      "metadata": {
        "id": "QegeZvzn0Sr4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluación del Modelo**"
      ],
      "metadata": {
        "id": "hPdNl89V2lMy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se calculan las métricas del Modelo\n",
        "accuracy_tfidf_B = accuracy_score(y_test, y_pred)\n",
        "precision_tfidf_B = precision_score(y_test, y_pred)\n",
        "recall_tfidf_B = recall_score(y_test, y_pred)\n",
        "f1_tfidf_B = f1_score(y_test, y_pred)\n",
        "y_proba_tfidf_B = model.predict_proba(X_test_tfidf)[:, 1]   # Probabilidades para la clase positiva\n",
        "#y_proba_tfidf_B = model.predict_proba(X_test_tfidf)\n",
        "#y_proba_tfidf_B = model.predict_proba(X_test_scaled)\n",
        "roc_auc_tfidf_B = roc_auc_score(y_test, y_proba_tfidf_B)\n",
        "\n",
        "# Almaceno las métricas del modelo\n",
        "metricas_modelos['RL_TFIDF_Binario'] = {\n",
        "    'Accuracy': accuracy_tfidf_B,\n",
        "    'Precision': precision_tfidf_B,\n",
        "    'Recall': recall_tfidf_B,\n",
        "    'F1 Score': f1_tfidf_B,\n",
        "    'ROC AUC': roc_auc_tfidf_B\n",
        "}\n",
        "\n",
        "print(\"Métricas del Modelo con TF-IDF binario\")\n",
        "print(f\"- Accuracy: {accuracy_tfidf_B:.3f}\")\n",
        "print(f\"- Precisión: {precision_tfidf_B:.3f}\")\n",
        "print(f\"- Recall: {recall_tfidf_B:.3f}\")\n",
        "print(f\"- F1 Score: {f1_tfidf_B:.3f}\")\n",
        "print(f\"- ROC AUC Score: {roc_auc_tfidf_B:.3f}\")\n",
        "\n",
        "# Reporte por clase\n",
        "print(\"\\n\\nReporte de Clasificación por Clase:\\n\")\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "bSsL1UMf2lee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "💡 Como era de esperar, las métricas mejoran considerablemente:\n",
        "* El modelo clasifica correctamente el 92.4% de los casos, lo cual indica un rendimiento superior.\n",
        "* En promedio, cuando el modelo predice una clase, acierta el 93.1% de las veces (dado que no se contempla la clase 3-neutral).\n",
        "* El modelo logra recuperar el 98.7% de los casos reales, lo que indica que casi no deja casos sin detectar.\n",
        "* El equilibrio entre precisión y recall óptimo.\n",
        "* El ROC AUC Score es alto, lo que indica que el modelo tiene buena capacidad para distinguir entre clases."
      ],
      "metadata": {
        "id": "yUQbjkoA6FNY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel('Predicción')\n",
        "plt.ylabel('Valor Real')\n",
        "plt.title('Matriz de Confusión')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6iP7wpwM65Be"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "💡 Luego, el modelo tiene muy buen desempeño para la clase 1, con una alta cantidad de aciertos (3442) y pocos errores (44). Aunque para la clase 0 el rendimiento es más bajo: hay más errores (256) que aciertos (222), lo que indica que el modelo tiende a sobrepredecir la clase 1. Esto podría deberse a un desequilibrio en los datos, dado que la clase 1 es mucho más frecuente que la clase 0."
      ],
      "metadata": {
        "id": "xPZkeFmr7XyY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **◼️ BOW - BAG OF WORDS**\n",
        "----\n",
        "\n",
        "Para abordar el problema de clasificación de reseñas según su calificación, se implementó un modelo de **Regresión Logística** utilizando la técnica **Bag Of Words (BoW)**. Este enfoque permite transformar el texto en una representación numérica basada en la frecuencia de aparición de cada palabra, sin considerar su orden ni contexto.\n",
        "\n",
        "Una vez vectorizados los textos, se entrenó el modelo para predecir la variable Rating, permitiendo identificar patrones lingüísticos asociados a distintas valoraciones.\n",
        "\n",
        "Este modelo sirve como punto de partida para evaluar cómo el contenido textual de las reseñas se relaciona con la percepción del usuario, y qué tan bien puede predecirse esa percepción a partir del lenguaje utilizado."
      ],
      "metadata": {
        "id": "A0FFT9dZ77Yb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Entrenamiento del Modelo con el dataset original**\n",
        "\n",
        "Se toma el set de datos original con Ratings del 1 al 5 (multiclase)."
      ],
      "metadata": {
        "id": "B4--XuIqCtLU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se separan la variable dependiente (Review Text) y objetivo (Rating)\n",
        "X = dfReviews['Review Text']\n",
        "y = dfReviews['Rating']\n",
        "\n",
        "# Se divide el dataset en conjunto de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "vectorizador_bow = CountVectorizer()                    # Se inicializa el CountVectorizer (BoW)\n",
        "X_train_bow = vectorizador_bow.fit_transform(X_train)   # Se ajustan las reseñas de entrenamiento\n",
        "\n",
        "X_train_bow"
      ],
      "metadata": {
        "id": "4e4VwJpECO5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_bow = vectorizador_bow.transform(X_test)         # Se transforman las reseñas de prueba\n",
        "\n",
        "print(\"Vocabulario BoW:\", vectorizador_bow.get_feature_names_out())\n",
        "print(\"Matriz BoW de entrenamiento:\\n\", X_train_bow.toarray())"
      ],
      "metadata": {
        "id": "K7nIL-YRCUXY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se entrena el modelo de Regresión Logística con Bag of Words\n",
        "modelo_bow = LogisticRegression(max_iter=1000)\n",
        "modelo_bow.fit(X_train_bow, y_train)"
      ],
      "metadata": {
        "id": "WUX3d509CWpz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se hacen predicciones en el conjunto de prueba\n",
        "y_pred_bow = modelo_bow.predict(X_test_bow)"
      ],
      "metadata": {
        "id": "E3mMLT96CZSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se calculan las métricas del modelo\n",
        "accuracy_bow_M = accuracy_score(y_test, y_pred_bow)\n",
        "precision_bow_M = precision_score(y_test, y_pred_bow, average='weighted')   # Calcula la métrica multiclase con average='weighted'\n",
        "recall_bow_M = recall_score(y_test, y_pred_bow, average='weighted')         # Calcula la métrica multiclase con average='weighted'\n",
        "f1_bow_M = f1_score(y_test, y_pred_bow, average='weighted')                 # Calcula la métrica multiclase con average='weighted'\n",
        "#y_proba_M = modelo_bow.predict_proba(X_test_tfidf)[:, 1]                    # Probabilidades para la clase positiva\n",
        "#y_proba_M = modelo_bow.predict_proba(X_test_scaled)\n",
        "y_proba_bow_M = modelo_bow.predict_proba(X_test_bow)\n",
        "roc_auc_bow_M = roc_auc_score(y_test, y_proba_bow_M, multi_class='ovr', average='weighted') # Calcula la métrica multiclase con average='weighted'\n",
        "\n",
        "# Almaceno las métricas del modelo\n",
        "metricas_modelos['RL_BOW_Multiclase'] = {\n",
        "    'Accuracy': accuracy_bow_M,\n",
        "    'Precision': precision_bow_M,\n",
        "    'Recall': recall_bow_M,\n",
        "    'F1 Score': f1_bow_M,\n",
        "    'ROC AUC': roc_auc_bow_M\n",
        "}\n",
        "\n",
        "print(\"Métricas del Modelo con Bag of Words (BoW) multiclase\")\n",
        "print(f\"- Accuracy: {accuracy_bow_M:.3f}\")\n",
        "print(f\"- Precisión: {precision_bow_M:.3f}\")\n",
        "print(f\"- Recall: {recall_bow_M:.3f}\")\n",
        "print(f\"- F1 Score: {f1_bow_M:.3f}\")\n",
        "print(f\"- ROC AUC Score: {roc_auc_bow_M:.3f}\")\n",
        "\n",
        "# Reporte por clase\n",
        "print(\"\\n\\nReporte de Clasificación por Clase:\\n\")\n",
        "print(classification_report(y_test, y_pred_bow))"
      ],
      "metadata": {
        "id": "mcBuXgEcC9b5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Clases en y:\", y.unique())"
      ],
      "metadata": {
        "id": "7EH3bZ6mCPFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Matriz de confusión\n",
        "cm = confusion_matrix(y_test, y_pred_bow)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel('Predicción')\n",
        "plt.ylabel('Real')\n",
        "plt.title('Matriz de Confusión')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7_T1Er3dyhqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Entrenamiento del Modelo con el dataset de clasificación binaria (positiva/negativa)**"
      ],
      "metadata": {
        "id": "EPaMDtdPC1Qg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se separan la variable dependiente (Review Text) y objetivo (Rating)\n",
        "X = df['Review Text']\n",
        "y = df['SentimentValue']\n",
        "\n",
        "# Se divide el dataset en conjunto de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "vectorizador_bow = CountVectorizer()                    # Se inicializa el CountVectorizer (BoW)\n",
        "X_train_bow = vectorizador_bow.fit_transform(X_train)   # Se ajustan las reseñas de entrenamiento\n",
        "\n",
        "X_train_bow"
      ],
      "metadata": {
        "id": "cDQKMuis9Bg6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_bow = vectorizador_bow.transform(X_test)         # Se transforman las reseñas de prueba\n",
        "\n",
        "print(\"Vocabulario BoW:\", vectorizador_bow.get_feature_names_out())\n",
        "print(\"Matriz BoW de entrenamiento:\\n\", X_train_bow.toarray())"
      ],
      "metadata": {
        "id": "CCE4wo589NHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se entrena el modelo de Regresión Logística con Bag of Words\n",
        "modelo_bow = LogisticRegression(max_iter=1000)\n",
        "modelo_bow.fit(X_train_bow, y_train)"
      ],
      "metadata": {
        "id": "1JaEVkJw9Xe-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se hacen predicciones en el conjunto de prueba\n",
        "y_pred_bow = modelo_bow.predict(X_test_bow)"
      ],
      "metadata": {
        "id": "da0ASIuY9d60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se calculan las métricas del modelo\n",
        "accuracy_bow_B = accuracy_score(y_test, y_pred_bow)\n",
        "precision_bow_B = precision_score(y_test, y_pred_bow)\n",
        "recall_bow_B = recall_score(y_test, y_pred_bow)\n",
        "f1_bow_B = f1_score(y_test, y_pred_bow)\n",
        "y_proba_bow_B = modelo_bow.predict_proba(X_test_bow)\n",
        "roc_auc_bow_B = roc_auc_score(y_test, y_proba_bow_B[:, 1])   # Para calcular el ROC AUC en binaria, se usa solo la probabilidad de la clase positiva (1)\n",
        "\n",
        "# Almaceno las métricas del modelo\n",
        "metricas_modelos['RL_BOW_Binario'] = {\n",
        "    'Accuracy': accuracy_bow_B,\n",
        "    'Precision': precision_bow_B,\n",
        "    'Recall': recall_bow_B,\n",
        "    'F1 Score': f1_bow_B,\n",
        "    'ROC AUC': roc_auc_bow_B\n",
        "}\n",
        "\n",
        "print(\"Métricas del Modelo con Bag of Words (BoW) en binaria:\")\n",
        "print(f\"- Accuracy: {accuracy_bow_B:.3f}\")\n",
        "print(f\"- Precisión: {precision_bow_B:.3f}\")\n",
        "print(f\"- Recall: {recall_bow_B:.3f}\")\n",
        "print(f\"- F1 Score: {f1_bow_B:.3f}\")\n",
        "print(f\"- ROC AUC Score: {roc_auc_bow_B:.3f}\")\n",
        "\n",
        "# Reporte por clase\n",
        "print(\"\\n\\nReporte de Clasificación por Clase:\\n\")\n",
        "print(classification_report(y_test, y_pred_bow))"
      ],
      "metadata": {
        "id": "xnQxei8BwWF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Matriz de confusión\n",
        "cm = confusion_matrix(y_test, y_pred_bow)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel('Predicción')\n",
        "plt.ylabel('Real')\n",
        "plt.title('Matriz de Confusión')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "xVc62v8qwg_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **◼️ COMPARACIÓN DE LOS MODELOS**\n",
        "----\n"
      ],
      "metadata": {
        "id": "rRa2MQXQAtYv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_comparacion = pd.DataFrame(metricas_modelos).T  # Transponer para que los modelos sean filas\n",
        "print(df_comparacion.round(3))"
      ],
      "metadata": {
        "id": "QLP3gSmuwh3E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelo TF-IDF\n",
        "\n",
        "df['SentimentValue'] = np.where(df['Sentiment'] == \"Positivo\", 1, 0)\n",
        "\n",
        "# Se dividen los datos en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['Review Text'], df['SentimentValue'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Se divide el dataset en conjunto de entrenamiento y prueba\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "vectorizador_tfidf = TfidfVectorizer(max_features=5000)       # Inicialización del vectorizador TF-IDF\n",
        "X_train_tfidf = vectorizador_tfidf.fit_transform(X_train)     # Se ajustan y transforman las reseñas de entrenamiento\n",
        "#X_test_tfidf = vectorizador_tfidf.transform(X_test)           # Se transforman las reseñas de prueba\n",
        "modelo_tfidf = LogisticRegression(max_iter=1000)              # Se instancia el modelo\n",
        "modelo_tfidf.fit(X_train_tfidf, y_train)                      # Se entrena el modelo (aprende) a partir de los datos de entrenamiento\n",
        "y_pred_tfidf = modelo_tfidf.predict(X_test_tfidf)             # Se hacen  predicciones en el conjunto de prueba"
      ],
      "metadata": {
        "id": "m0EDYjAv9l2b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelo BOW\n",
        "\n",
        "# Se separan la variable dependiente (Review Text) y objetivo (SentimentValue)\n",
        "X = df['Review Text']\n",
        "y = df['SentimentValue']\n",
        "\n",
        "# Se divide el dataset en conjunto de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "vectorizador_bow = CountVectorizer()                          # Se inicializa el CountVectorizer (BoW)\n",
        "X_train_bow = vectorizador_bow.fit_transform(X_train)         # Se ajustan las reseñas de entrenamiento\n",
        "modelo_bow = LogisticRegression(max_iter=1000)                # Se instancia el modelo\n",
        "modelo_bow.fit(X_train_bow, y_train)                          # Se entrena el modelo\n",
        "y_pred_bow = modelo_bow.predict(X_test_bow)                   # Se hacen predicciones en el conjunto de prueba"
      ],
      "metadata": {
        "id": "gtobXoX89mX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para predecir una nueva reseña\n",
        "def predecir_reseña(nueva_reseña, modelo_bow, modelo_tfidf, vectorizador_bow, vectorizador_tfidf):\n",
        "    # Preprocesar la nueva reseña\n",
        "    nueva_reseña_bow = vectorizador_bow.transform([nueva_reseña])\n",
        "    nueva_reseña_tfidf = vectorizador_tfidf.transform([nueva_reseña])\n",
        "\n",
        "    prediccion_bow = modelo_bow.predict(nueva_reseña_bow)           # Predicción usando Bag of Words\n",
        "    prediccion_tfidf = modelo_tfidf.predict(nueva_reseña_tfidf)     # Predicción usando TF-IDF\n",
        "\n",
        "    # Mostrar resultados\n",
        "    print(f\"Reseña ingresada: {nueva_reseña}\")\n",
        "    print(f\"Predicción con Bag of Words: {'Positiva' if prediccion_bow[0] == 1 else 'Negativa'}\")\n",
        "    print(f\"Predicción con TF-IDF: {'Positiva' if prediccion_tfidf[0] == 1 else 'Negativa'}\")\n",
        "\n",
        "\n",
        "# Simular ingreso de nueva reseña por el usuario\n",
        "nueva_reseña = input(\"Ingresa una reseña de indumentaria: \")\n",
        "predecir_reseña(nueva_reseña, modelo_bow, modelo_tfidf, vectorizador_bow, vectorizador_tfidf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "AqIjZTVc9t3x",
        "outputId": "90a8e9c6-6368-4763-c6b4-a738fd635a8b"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3806727524.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Simular ingreso de nueva reseña por el usuario\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mnueva_reseña\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Ingresa una reseña de indumentaria: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mpredecir_reseña\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnueva_reseña\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodelo_bow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodelo_tfidf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectorizador_bow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectorizador_tfidf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"1\" href=\"#introduccion\"></a>\n",
        "# <div style=\"padding:20px;color:yellow;margin:0;font-size:30px;font-family:Verdana;text-align:center;display:fill;border-radius:5px;background-color:#333333;overflow:hidden\"><b>CONCLUSIÓN </b></div>"
      ],
      "metadata": {
        "id": "yIT5mKx0Jcl6"
      }
    }
  ]
}