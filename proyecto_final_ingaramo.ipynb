{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPxHT9Rq0RY2i2nsawxnC6v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eugeinga/CODER-DataScienceIII/blob/main/proyecto_final_ingaramo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DATA SCIENCE III: NLP, Deep learning y Redes Neuronales B√°sicas**\n"
      ],
      "metadata": {
        "id": "4EGej2tT5tME"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Portada](https://github.com/eugeinga/CODER-DataScienceII/raw/main/IMG/IMG-BannerCODER.jpg)"
      ],
      "metadata": {
        "id": "BMi28owzGtgj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Comisi√≥n:** 74560\n",
        "* **Profesor:** Ezequiel Juan Bassano\n",
        "* **Tutor:** Federico Gravina\n",
        "* **Estudiante:** [Eugenia Ingaramo](https://www.linkedin.com/in/eugeniaingaramo/)"
      ],
      "metadata": {
        "id": "uwWn4Qc15x1d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PROYECTO FINAL: An√°lisis de rese√±as sobre tiendas online de ropa para mujer**"
      ],
      "metadata": {
        "id": "R23CcA304Dec"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"1\"></a>\n",
        "# <div style=\"padding:20px;color:yellow;margin:0;font-size:30px;font-family:Verdana;text-align:center;display:fill;border-radius:5px;background-color:#333333;overflow:hidden\"><b>CONTENIDO DEL PROYECTO </b></div>"
      ],
      "metadata": {
        "id": "pjiNlhSBn-2T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"toc\">\n",
        "  <ul>\n",
        "    <li>INTRODUCCI√ìN</li>\n",
        "    <li>OBJETIVOS e HIP√ìTESIS</li>\n",
        "    <li>EL SET DE DATOS</li>\n",
        "    <li>PRE-PROCESAMIENTO DE DATOS\n",
        "    <ul>\n",
        "      <li>Librer√≠as a utilizar</li>\n",
        "      <li>Carga de Datos</li>\n",
        "      <li>Data Wrangling\n",
        "        <ul>\n",
        "          <li>Valores Duplicados</li>\n",
        "          <li>Valores Faltantes</li>\n",
        "          <li>Transformaci√≥n de datos</li>\n",
        "        </ul>\n",
        "      </li>\n",
        "      <li>Limpieza de texto</li>\n",
        "      <ul>\n",
        "          <li>Normalizaci√≥n</li>\n",
        "          <li>Signos de Puntuaci√≥n</li>\n",
        "          <li>Tokenizaci√≥n</li>\n",
        "          <li>Stopwords</li>\n",
        "          <li>Steming</li>\n",
        "          <li>Lematizaci√≥n</li>\n",
        "        </ul>\n",
        "    </ul>\n",
        "    </li>\n",
        "    <li>AN√ÅLISIS EXPLORATORIO DE DATOS (EDA)\n",
        "      <ul>\n",
        "        <li>Frecuencia de las palabras</li>\n",
        "        <li>Nubes de palabras y n-gramas</li>\n",
        "        <li>An√°lisis de Sentimientos</li>\n",
        "      </ul>          \n",
        "    <li>MODELADO\n",
        "      <ul>\n",
        "        <li>TF-IDF - Term Frequency-Inverse Document Frequency</li>\n",
        "        <li>Bag Of Words (BOW)</li>  \n",
        "      </ul>\n",
        "    <li>CONCLUSI√ìN</li>\n",
        "    <li>REFERENCIAS</li>\n",
        "  </ul>\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "szp0-J9ZoJTs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"1\" href=\"#introduccion\"></a>\n",
        "# <div style=\"padding:20px;color:yellow;margin:0;font-size:30px;font-family:Verdana;text-align:center;display:fill;border-radius:5px;background-color:#333333;overflow:hidden\"><b>INTRODUCCION </b></div>"
      ],
      "metadata": {
        "id": "LPhlcsIJejhK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Datset Cover](https://github.com/eugeinga/CODER-DataScienceIII/raw/main/IMG-Indumentaria.jpg)"
      ],
      "metadata": {
        "id": "J6pay3sSBpXv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En el competitivo mundo del e-commerce de indumentaria femenina, entender las opiniones de las clientas es clave para mejorar la experiencia de compra, optimizar el cat√°logo de productos y aumentar la fidelizaci√≥n. Sin embargo, las rese√±as suelen estar en formato texto no estructurado, lo que dificulta su an√°lisis masivo.\n",
        "Este proyecto busca transformar estas rese√±as en informaci√≥n valiosa, identificando patrones de satisfacci√≥n e insatisfacci√≥n y construyendo un modelo que permita clasificar autom√°ticamente las opiniones como positivas o negativas."
      ],
      "metadata": {
        "id": "48SU4MbJguaY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"1\"></a>\n",
        "# <div style=\"padding:20px;color:yellow;margin:0;font-size:30px;font-family:Verdana;text-align:center;display:fill;border-radius:5px;background-color:#333333;overflow:hidden\"><b>OBJETIVO</b></div>"
      ],
      "metadata": {
        "id": "i9n9VKMRg7ZA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El presente trabajo tiene por objeto analizar y modelar rese√±as de indumentaria femenina para:\n",
        "\n",
        "* Aplicar t√©cnicas de Procesamiento de Lenguaje Natural (NLP) que permitan extraer insights relevantes.\n",
        "\n",
        "* Desarrollar un modelo de clasificaci√≥n supervisado que prediga la polaridad de una rese√±a (positiva/negativa) a partir de su texto."
      ],
      "metadata": {
        "id": "TWxPDtfXhCqr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"1\"></a>\n",
        "# <div style=\"padding:20px;color:yellow;margin:0;font-size:30px;font-family:Verdana;text-align:center;display:fill;border-radius:5px;background-color:#333333;overflow:hidden\"><b>EL SET DE DATOS </b></div>"
      ],
      "metadata": {
        "id": "RUA-IKofnavn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **‚óºÔ∏è ORIGEN DE LOS DATOS**\n",
        "----\n",
        "\n",
        "**Women‚Äôs Clothing E-Commerce Reviews**, disponible p√∫blicamente en Kaggle:\n",
        "<https://www.kaggle.com/datasets/nicapotato/womens-ecommerce-clothing-reviews>\n",
        "\n",
        "Este es un conjunto de datos de comercio electr√≥nico de ropa femenina que gira en torno a las rese√±as escritas por los clientes."
      ],
      "metadata": {
        "id": "vabLk05cV-Dm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **‚óºÔ∏è VARIABLES**\n",
        "----\n",
        "Este conjunto de datos incluye 23.486 filas y 10 variables de caracter√≠sticas. Cada fila corresponde a una rese√±a de un cliente e incluye las siguientes variables:\n",
        "\n",
        "* **ID de la prenda:** variable categ√≥rica entera que hace referencia a la prenda espec√≠fica que se rese√±a.\n",
        "* **Edad:** variable entera positiva que indica la edad del rese√±ador.\n",
        "* **T√≠tulo:** Variable de cadena para el t√≠tulo de la rese√±a.\n",
        "* **Texto de la rese√±a:** Variable de cadena para el cuerpo de la rese√±a.\n",
        "* **Calificaci√≥n:** Variable entera ordinal positiva para la puntuaci√≥n del producto otorgada por el cliente, desde 1 (peor) hasta 5 (mejor).\n",
        "* **IND recomendado:** Variable binaria que indica si el cliente recomienda el producto, donde 1 significa recomendado y 0 no recomendado.\n",
        "* **Recuento de comentarios positivos:** N√∫mero entero positivo que documenta el n√∫mero de otros clientes que consideraron positiva esta rese√±a.\n",
        "* **Nombre de la divisi√≥n:** Nombre categ√≥rico de la divisi√≥n de alto nivel del producto.\n",
        "* **Nombre del departamento:** Nombre categ√≥rico del departamento del producto.\n",
        "* **Nombre de la clase:** Nombre categ√≥rico de la clase del producto.\n",
        "\n",
        "\n",
        "Para la clasificaci√≥n se crea una variable binaria objetivo \"Sentiment\":\n",
        "* 1 (Positivo) = Rating 4 o 5.\n",
        "* 0 (Negativo) = Rating 1 o 2.\n",
        "\n",
        "Se excluir√°n las rese√±as con rating 3 (neutral)."
      ],
      "metadata": {
        "id": "0vLk_RRslv68"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"1\"></a>\n",
        "# <div style=\"padding:20px;color:yellow;margin:0;font-size:30px;font-family:Verdana;text-align:center;display:fill;border-radius:5px;background-color:#333333;overflow:hidden\"><b>PRE-PROCESAMIENTO DE DATOS </b></div>"
      ],
      "metadata": {
        "id": "678TtHrMqL3f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **‚óºÔ∏è LIBRER√çAS A UTILIZAR**\n",
        "----"
      ],
      "metadata": {
        "id": "VWPfh-GvWPST"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZcCNhdHM_4K_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd                                           # manejo de datos\n",
        "import numpy as np                                            # manejo de arreglos\n",
        "import missingno as msno                                      # visualizaci√≥n de datos faltantes\n",
        "import re                                                     # Para trabajar con expresiones regulares\n",
        "import chardet                                                # Para identificar el encoding del archivo de datos\n",
        "import requests                                               # Para salvar limitaciones de acceso a internet del entorno de ejecuci√≥n\n",
        "\n",
        "import nltk                                                   # Biblioteca para procesamiento de lenguaje natural - NATURAL LANGUAGE TOOLKIT\n",
        "nltk.download('punkt')                                        # Descarga el paquete de tokenizaci√≥n de NLTK\n",
        "nltk.download('punkt_tab')                                    # Descarga el paquete de tokenizaci√≥n de NLTK\n",
        "nltk.download('stopwords')                                    # Descarga el paquete de stopwords de NLTK\n",
        "nltk.download('wordnet')                                      # Descarga el paquete de WordNet de NLTK (base de datos l√©xica para lematizaci√≥n en ingl√©s)\n",
        "from nltk.corpus import stopwords                             # Para acceder a listas de palabras vac√≠as (stopwords) en distintos idiomas\n",
        "from nltk.tokenize import word_tokenize                       # Desde el m√≥dulo tokenize de NLTK, se importa s√≥lo la funci√≥n word_tokenize\n",
        "from nltk.stem import PorterStemmer                           # Desde el m√≥dulo stem de NLTK, se importa s√≥lo la funci√≥n PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer                       # Desde el m√≥dulo stem de NLTK, se importa s√≥lo la funci√≥n WordNetLemmatizer\n",
        "\n",
        "from wordcloud import WordCloud                               # Para trabajar con nubes de palabras\n",
        "from textblob import TextBlob                                 # Para an√°lisis de sentimientos\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer   # Para convertir texto en vectores/matrices de frecuencia (BOW: Bag Of Words)\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer   # Para generar frecuencias TF-IDF (frecuencia inversa de documentos) y convertir texto en una matriz num√©rica\n",
        "from sklearn.model_selection import train_test_split          # Para dividir los datos en entrenamiento y prueba\n",
        "from sklearn.linear_model import LogisticRegression           # Algoritmo de clasificaci√≥n binaria\n",
        "from sklearn.preprocessing import StandardScaler              # Para escalar los datos y mejorar la estabilidad del entrenamiento\n",
        "\n",
        "from sklearn.metrics import classification_report             # Para calcular las m√©tricas del modelo\n",
        "from sklearn.metrics import accuracy_score                    # Para calcular qu√© tan bien predice el modelo en datos nuevos (exactitud). Predicciones correctas / Total de casos.\n",
        "from sklearn.metrics import precision_score                   # Para calcular el costo de un falso positivo. Proporci√≥n de predicciones positivas que son realmente positivas.\n",
        "from sklearn.metrics import recall_score                      # Para calcular cu√°ntos de los casos positivos reales fueron capturados por el modelo.\n",
        "from sklearn.metrics import f1_score                          # Para calcular la relaci√≥n entre precisi√≥n y recall.\n",
        "from sklearn.metrics import confusion_matrix                  # Para calcular la Matriz de Confusi√≥n (Muestra los aciertos y errores del modelo organizados por clase)\n",
        "from sklearn.metrics import roc_auc_score                     # Para calcular qu√© tan bien el modelo separa las clases.\n",
        "\n",
        "import matplotlib.pyplot as plt                               # Para crear gr√°ficos y visualizaciones\n",
        "import seaborn as sns                                         # Para crear gr√°ficos y visualizaciones\n",
        "#from seaborn import lmplot\n",
        "#import matplotlib.style as style\n",
        "\n",
        "#from sklearn.preprocessing import LabelEncoder      # conversi√≥n de variables categ√≥ricas\n",
        "#from sklearn.preprocessing import StandardScaler    # escalado de datos\n",
        "#from sklearn.preprocessing import RobustScaler      # escalado de datos\n",
        "\n",
        "#import scipy.stats as stats                         # an√°lisis estad√≠stico\n",
        "#from scipy.stats import shapiro                     # Test estad√≠stico de Normalidad\n",
        "\n",
        "#import statsmodels.api as sm                        # Gr√°fico QQ-Plot\n",
        "#from statsmodels.regression.linear_model import OLS # para an√°lisis de multicolinealidad (VIF)\n",
        "#from statsmodels.tools.tools import add_constant    # para an√°lisis de multicolinealidad (VIF)\n",
        "\n",
        "#from sklearn.model_selection import cross_val_score\n",
        "#from sklearn.model_selection import GridSearchCV\n",
        "#from sklearn.ensemble import RandomForestRegressor  # Random Forest\n",
        "#from sklearn.svm import SVC                         # Support Vector Machine (SVM) para Clasificaci√≥n\n",
        "#from sklearn.neighbors import KNeighborsRegressor   # K-Nearest Neighbor (KNN)\n",
        "#from sklearn.pipeline import Pipeline, make_pipeline\n",
        "#from sklearn.metrics import classification_report, mean_squared_error\n",
        "#from sklearn.inspection import permutation_importance\n",
        "\n",
        "#import statsmodels.api as sm\n",
        "#from statsmodels.miscmodels.ordinal_model import OrderedModel # Regresi√≥n Log√≠stica Ordinal\n",
        "\n",
        "#sns.set_theme(style=\"whitegrid\", palette=\"pastel\") # Estilo de seaborn\n",
        "#custom_palette = {\n",
        "#    0: '#ffb482',  # Tipo de vino: RED (type=0) Color Naranja\n",
        "#    1: '#a1c9f4',  # Tipo de vino: WHITE (type=1) Color Azul\n",
        "#    'red': '#ffb482',  # Tipo de vino: RED (type=0) Color Naranja\n",
        "#    'white': '#a1c9f4'  # Tipo de vino: WHITE (type=1) Color Azul\n",
        "#}\n",
        "\n",
        "#sns.color_palette(\"pastel\")\n",
        "#sns.color_palette(\"pastel\").as_hex()\n",
        "#sns.color_palette(palette='pastel', as_cmap=True)\n",
        "\n",
        "import warnings                                               # Para tratamiento de errores/alertas\n",
        "#warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **‚óºÔ∏è CARGA DE DATOS**\n",
        "----\n",
        "\n",
        "Como primera medida, se detecta el encoding del archivo a utilizar con la librer√≠a \"chardet\""
      ],
      "metadata": {
        "id": "6IMIS-uEiM5Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://raw.githubusercontent.com/eugeinga/CODER-DataScienceIII/main/Womens%20Clothing%20E-Commerce%20Reviews.csv\" # Descarga el contenido del archivo desde la URL\n",
        "response = requests.get(url)\n",
        "result = chardet.detect(response.content[:10000])                                                                         # Detecta el encoding usando chardet\n",
        "print(result)"
      ],
      "metadata": {
        "id": "Z30fgcY9AcFs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aunque chardet detect√≥ 'ascii' con alta confianza, ese encoding no es suficiente para leer correctamente el archivo, posiblemente caracteres especiales (como acentos) que no est√°n en el conjunto ASCII. Por lo tanto, har√© uso de ISO-8859-1."
      ],
      "metadata": {
        "id": "ce5mjpaXC1l1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lectura del dataset con encoding='ISO-8859-1' para evitar errores de lectura cuando el archivo contiene caracteres especiales que no est√°n en ASCII o UTF-8.\n",
        "\n",
        "url=\"https://raw.githubusercontent.com/eugeinga/CODER-DataScienceIII/refs/heads/main/Womens%20Clothing%20E-Commerce%20Reviews.csv\"\n",
        "dfReviews=pd.read_csv(url,sep=',',header=0, encoding='ISO-8859-1')\n",
        "dfReviews.head()"
      ],
      "metadata": {
        "id": "w0ux86UfDkJD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **‚óºÔ∏è DATA WRANGLING**\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "52LXCUzF3VDW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El **Data Wrangling** consiste en limpiar, transformar y estructurar los datos para que sean m√°s utilizables y valiosos. Este proceso es esencial porque los datos en su forma original a menudo est√°n desordenados, incompletos o contienen errores que pueden afectar la calidad del an√°lisis.\n",
        "\n",
        "Como parte de esta etapa se proceder√° a:\n",
        "- Identificar valores duplicados\n",
        "- Identificar valores faltantes\n",
        "- Transformar datos (normalizaci√≥n, estandarizaci√≥n, etc.).\n",
        "\n",
        "En este caso se trabaja con un √∫nico dataset por lo que no ser√° necesario combinar/concatenar ficheros."
      ],
      "metadata": {
        "id": "WwPtH_Lc6I0w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Informaci√≥n de resumen del dataset\n",
        "dfReviews.info()"
      ],
      "metadata": {
        "id": "swUMxE7mEatR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El dataset bajo estudio cuenta con 23486 filas y 10 columnas de las cuales 9 corresponden a variables independientes a analizar y 1 a la variable dependiente u objetivo."
      ],
      "metadata": {
        "id": "_8XdPQc_qdEH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cardinalidad de las variables\n",
        "\n",
        "cardinalidad = pd.DataFrame({'Cantidad' : dfReviews.nunique(), 'Porcentaje' : (dfReviews.nunique()) / (dfReviews.shape[0]) * (100)}).round(2)\n",
        "cardinalidad"
      ],
      "metadata": {
        "id": "TxU-xewjhH1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **‚óæ VALORES DUPLICADOS**\n",
        "\n",
        "##### Se identifican y remueven de los registros duplicados"
      ],
      "metadata": {
        "id": "N3J0mGR_LTkO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Dimensiones del dataset original: \", dfReviews.shape)\n",
        "dfReviews.duplicated().value_counts()\n",
        "dfReviews.drop_duplicates(inplace=True)\n",
        "print(\"Dimensiones del dataset sin filas duplicadas: \", dfReviews.shape)"
      ],
      "metadata": {
        "id": "6xnagbRzrBow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El dataset no tiene registros duplicadas que eliminar."
      ],
      "metadata": {
        "id": "U24VOaI1rI0E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **‚óæ VALORES FALTANTES**\n",
        "\n",
        "Se identifican los valores nulos en cada una de las columnas del dataset."
      ],
      "metadata": {
        "id": "NkPHWMfUJ_f4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Contabilizo los datos nulos/faltantes por columna.\n",
        "\n",
        "pd.DataFrame({'Cant.NAN' : dfReviews.isna().sum(), '%NAN' : dfReviews.isna().sum() / len(dfReviews) * (100)}).round(2)"
      ],
      "metadata": {
        "id": "Uri8fSIReBF5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "msno.matrix(dfReviews)"
      ],
      "metadata": {
        "id": "MgXKUH8bZWsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se eliminan los registros donde el campo \"Review Text\" sea nulo dado que no aportan valor al an√°lisis a realizar."
      ],
      "metadata": {
        "id": "LTaemB_BZS1q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Dimensiones del dataset antes de la remoci√≥n de valores faltantes: \", dfReviews.shape)\n",
        "dfReviews.dropna(subset=['Review Text'], inplace=True)\n",
        "print(\"Dimensiones del dataset sin valores faltantes en 'Review Text': \", dfReviews.shape)"
      ],
      "metadata": {
        "id": "YO6sVW5HZkom"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se determina la longitud m√≠nima, m√°xima y promedio de la variable \"Review Text\":"
      ],
      "metadata": {
        "id": "TIWltp7G9Q8S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dfReviews[\"review_length\"] = dfReviews[\"Review Text\"].apply(len)\n",
        "#dfReviews[\"review_length\"] = dfReviews[\"Review Text\"].fillna(\"\").apply(len)\n",
        "\n",
        "max_length = dfReviews[\"review_length\"].max()\n",
        "min_length = dfReviews[\"review_length\"].min()\n",
        "avg_length = dfReviews[\"review_length\"].mean()\n",
        "\n",
        "print(f\"Longitud m√°xima de rese√±as: {max_length}\")\n",
        "print(f\"Longitud m√≠nima de rese√±as: {min_length}\")\n",
        "print(f\"Longitud promedio de rese√±as: {avg_length:.2f}\")"
      ],
      "metadata": {
        "id": "27rvZXU89X9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **‚óæ TRANSFORMACI√ìN DE DATOS**\n",
        "\n",
        "Como parte del proceso de transformaci√≥n de datos se crea la variable binaria \"Sentiment\" a partir de la variable \"Rating\" asumiendo ratings 4 y 5 como positivos, 1 y 2 como negativos, descartando ratings 3."
      ],
      "metadata": {
        "id": "fJ6LxzV82Ji4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = dfReviews[dfReviews['Rating'] != 3].copy()\n",
        "df['Sentiment'] = np.where(df['Rating'] >= 4, \"Positivo\", \"Negativo\")\n",
        "df['Sentiment'].value_counts(normalize=True)"
      ],
      "metadata": {
        "id": "TrFD_PAH26At"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **‚óºÔ∏è LIMPIEZA DEL TEXTO**\n"
      ],
      "metadata": {
        "id": "izIMQm7ELXQi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **‚óæ NORMALIZACI√ìN**\n",
        "\n",
        "Se **normalizan** los valores pasando todo el texto a min√∫scula:"
      ],
      "metadata": {
        "id": "Kh_SddD-3n5f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Review_lower'] = df['Review Text'].apply(lambda text: text.lower())"
      ],
      "metadata": {
        "id": "cA5FzIa03zZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **‚óæ SIGNOS DE PUNTUACI√ìN**\n",
        "\n",
        "Se eliminan **signos de puntuaci√≥n**:"
      ],
      "metadata": {
        "id": "yIYnacAF48Bd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_punctuation(text):\n",
        "    return re.sub(r'[^a-zA-Z0-9\\s]', '', text)                          # Expresi√≥n regular para reemplazar cualquier signo de puntuaci√≥n o s√≠mbolo no alfanum√©rico\n",
        "\n",
        "df['Review_puntuacion'] = df['Review_lower'].apply(remove_punctuation)  # Aplicar la funci√≥n a la columna 'review_lower'"
      ],
      "metadata": {
        "id": "4lzTfpX_469d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **‚óæ TOKENIZACI√ìN**\n",
        "\n",
        "Se **tokenizan** los valores de la columna \"Review Text\" para dividir el texto en unidades peque√±as (tokens) a fin de poder trabajar con cada palabra por separado (contar frecuencias, aplicar modelos, buscar significados, etc.)\n"
      ],
      "metadata": {
        "id": "yfgrO54K7F4W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Review_tokenizado'] = df['Review_puntuacion'].apply(word_tokenize)"
      ],
      "metadata": {
        "id": "_JLQKQsJ7HKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **‚óæ STOPWORDS**\n",
        "\n",
        "Se remueven **stopwords**, aquellas  palabras vac√≠as que no aportan un valor significativo al an√°lisis del texto (ej.: art√≠culos, preposiciones, conjunciones y otros t√©rminos comunes que suelen ser irrelevantes para tareas de procesamiento de texto) y as√≠ mejorar la precisi√≥n en el an√°lisis de sentimientos, clasificaci√≥n de texto y b√∫squeda de informaci√≥n."
      ],
      "metadata": {
        "id": "Q-DQ23Ne_VTl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords_eng = stopwords.words('english')    # Para obtener el listado de stopwords en ingl√©s dado que las rese√±as est√°n en ese idioma\n",
        "print(stopwords_eng[:20])                     # Se muestran las primeras 20 stopwords"
      ],
      "metadata": {
        "id": "6-OMYFi2_hJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#stop_words = set(stopwords.words('english'))  # Se crea una lista de stopwords en ingl√©s usando NLTK\n",
        "stop_words = list(stopwords.words('english'))  # Se crea una lista de stopwords en ingl√©s usando NLTK\n",
        "\n",
        "# Se define una funci√≥n lamda para eliminar stopwords en cada fila de la columna 'Review_tokenizado'\n",
        "df['Review_tokenizado_sin_stopwords'] = df['Review_tokenizado'].apply(lambda tokens: [word for word in tokens if word not in stop_words])"
      ],
      "metadata": {
        "id": "-Cvcz7VLBKXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A fin de reducir la variabilidad de las palabras y facilitando el an√°lisis del texto se procede a realizar el steming y lematizaci√≥n de las palabras del campo \"Rreview Text\""
      ],
      "metadata": {
        "id": "BtLbJOSHGBan"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **‚óæ STEMMING**\n",
        "\n",
        "Se realiza el **stemming** de las palabras para reducirlas a su ra√≠z o forma base eliminando los sufijos de cada palabra."
      ],
      "metadata": {
        "id": "k-cMptPDHj0Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = PorterStemmer()   # Se inicializa el stemmer\n",
        "df['Review_stemming'] = df['Review_tokenizado_sin_stopwords'].apply(lambda tokens: [stemmer.stem(token) for token in tokens])  # Se aplica stemming a la columna 'Review_tokenizado_sin_stopwords'"
      ],
      "metadata": {
        "id": "pIUwtqFLGCfJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **‚óæ LEMATIZACI√ìN**\n",
        "\n",
        "Se realiza la **lematizaci√≥n** de las palabras a fin de reducirlas a su lema (forma base), manteniendo el significado gramatical correcto de las palabras."
      ],
      "metadata": {
        "id": "C9g_uAc2IC19"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()  # Se inicializa el lematizador\n",
        "df['Review_lematizacion'] = df['Review_tokenizado_sin_stopwords'].apply(lambda tokens: [lemmatizer.lemmatize(token) for token in tokens]) # Se aplica la lematizaci√≥n a la columna 'Review_tokenizado_sin_stopwords'"
      ],
      "metadata": {
        "id": "5r4szrFNIRxP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se previsualizan las columnas generadas como parte del proceso de limpieza del texto:"
      ],
      "metadata": {
        "id": "IXJUHiArKFXe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_colwidth', None) # Para configurar pandas para mostrar el contenido completo de las columnas\n",
        "df[[\"Review Text\", \"Review_lower\", \"Review_puntuacion\", \"Review_tokenizado\", \"Review_tokenizado_sin_stopwords\", \"Review_stemming\", \"Review_lematizacion\"]].head(5)"
      ],
      "metadata": {
        "id": "l1awNM417yyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.reset_option('display.max_colwidth')     # Restaura la configuraci√≥n predeterminada de pandas para el ancho de las columnas"
      ],
      "metadata": {
        "id": "8pbvG0p9KL4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"1\"></a>\n",
        "# <div style=\"padding:20px;color:yellow;margin:0;font-size:30px;font-family:Verdana;text-align:center;display:fill;border-radius:5px;background-color:#333333;overflow:hidden\"><b>AN√ÅLISIS EXPLORATORIO DE DATOS </b></div>"
      ],
      "metadata": {
        "id": "Q17TVK9uH4qm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se realiza un **An√°lisis Exploratorio de Datos** espec√≠fico para NLP.\n",
        "\n",
        "Como parte de esta etapa se proceder√° a:\n",
        "- Analizar la frecuencia de las palabras y n-gramas.\n",
        "- Generar nubes de palabras.\n",
        "- Identificar la distribuci√≥n de longitudes por clase.\n",
        "- Identificar palabras distintivas en cada clase."
      ],
      "metadata": {
        "id": "7t2NIXdE05UY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **‚óºÔ∏è FRECUENCIA DE PALABRAS**\n",
        "----"
      ],
      "metadata": {
        "id": "ccifFr5Uwpim"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se obtiene el listado de las palabras con mayor frecuencia:"
      ],
      "metadata": {
        "id": "vkWRahIlPmvg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "tokens_lematizados = [token for tokens_list in df['Review_lematizacion'] for token in tokens_list]  # Se unen todos los tokens lematizados en una sola lista\n",
        "frecuencia_palabras_lematizadas = Counter(tokens_lematizados)                                       # Se contabiliza la frecuencia de aparici√≥n de cada palabra\n",
        "frecuencia_palabras_lematizadas.most_common(20)                                                     # Se muestran las 20 palabras m√°s frecuentes"
      ],
      "metadata": {
        "id": "-9_XplqOPpz6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se grafica la distribuci√≥n de frecuencia de las palabras m√°s frecuentes para las palabras Lematizadas y las Originales"
      ],
      "metadata": {
        "id": "iUcejv73SZPt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(1, 2, figsize=(16, 6))  # 1 fila, 2 columnas\n",
        "\n",
        "tokens_sin_normalizar = [token for review in df['Review Text'] for token in review.split()]   # Tokenizaci√≥n sin normalizaci√≥n previa (sin pasar a min√∫sculas, sin quitar puntuaci√≥n)\n",
        "frecuencia_sin_normalizar = Counter(tokens_sin_normalizar)                                    # Se cuenta la frecuencia de cada palabra\n",
        "palabras_sin_norm, frecuencias_sin_norm = zip(*frecuencia_sin_normalizar.most_common(20))     # Se obtienen las 15 palabras m√°s comunes y sus frecuencias\n",
        "# Gr√°fica de tokenizaci√≥n sin normalizaci√≥n previa (derecha)\n",
        "axs[0].bar(palabras_sin_norm, frecuencias_sin_norm, color='red')\n",
        "axs[0].set_title('Top 15 Palabras Sin Normalizar')\n",
        "axs[0].set_xlabel('Palabras')\n",
        "axs[0].set_ylabel('Frecuencia')\n",
        "axs[0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "palabras_lem, frecuencias_lem = zip(*frecuencia_palabras_lematizadas.most_common(15)) # Se obtienen las 15 palabras m√°s comunes y sus frecuencias\n",
        "# Gr√°fica de tokenizaci√≥n sobre el texto lematizado (izquierda)\n",
        "axs[1].bar(palabras_lem, frecuencias_lem, color='green')\n",
        "axs[1].set_title('Top 15 Palabras Lematizadas')\n",
        "axs[1].set_xlabel('Palabras')\n",
        "axs[1].set_ylabel('Frecuencia')\n",
        "axs[1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "\n",
        "plt.tight_layout()  # Ajusta dise√±o para evitar superposici√≥n\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Td5rRsa9R2Lv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **‚óºÔ∏è NUBE DE PALABRAS Y N-GRAMAS**\n",
        "----"
      ],
      "metadata": {
        "id": "ZpIPfnT-I9Xc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se crean subplots de 1 fila, 2 columnas\n",
        "fig, axs = plt.subplots(1, 2, figsize=(18, 6))\n",
        "\n",
        "text_original = ' '.join(df['Review Text'].fillna('').astype(str))\n",
        "wordcloud_original = WordCloud(width=600, height=300, background_color='white').generate(text_original)                             # Se crea la nube de palabras con el texto original\n",
        "# Se grafica la nube de palabras original\n",
        "axs[0].imshow(wordcloud_original, interpolation='bilinear')\n",
        "axs[0].set_title('Nube de Palabras - Texto Original')\n",
        "#axs[0].axis('off')\n",
        "for spine in axs[0].spines.values():\n",
        "    spine.set_edgecolor('gray')\n",
        "    spine.set_linewidth(2)\n",
        "\n",
        "text_lematizado = ' '.join(df['Review_lematizacion'].fillna('').astype(str))\n",
        "wordcloud_lematizado = WordCloud(width=600, height=300, background_color='white', stopwords=stop_words).generate(text_lematizado)   # Se crea la nube de palabras con el texto lematizado sin stopwords\n",
        "# Se grafica la nube de palabras lematizadas\n",
        "axs[1].imshow(wordcloud_lematizado, interpolation='bilinear')\n",
        "axs[1].set_title('Nube de Palabras - Texto Lematizado')\n",
        "#axs[1].axis('off')\n",
        "for spine in axs[1].spines.values():\n",
        "    spine.set_edgecolor('gray')\n",
        "    spine.set_linewidth(2)\n",
        "\n",
        "plt.subplots_adjust(wspace=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tiCY9pk4SZXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se agregan algunas palabras a las stopwords para limpiar la nube de palabras y se vuelve a graficar."
      ],
      "metadata": {
        "id": "Z2wOIFuSY0cy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words.extend(['wear','would','one', 'dress', 'pant', 'skit', 'shirt', 'jacket', 'jean', 'sweater', 'legging', 'im']) # Agrega algunas palabras a las stopwords"
      ],
      "metadata": {
        "id": "Tv51RlrdQghJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_lematizado = ' '.join(df['Review_lematizacion'].fillna('').astype(str))  # Se crea una nueva wordcloud con el texto lematizado removiendo stopwords\n",
        "wordcloud = WordCloud(width=800, height=400, background_color='white', stopwords=stop_words).generate(text_lematizado)\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "spine.set_edgecolor('gray')\n",
        "spine.set_linewidth(2)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WZW8dVfwRU2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se generan nubes de palabras distintas seg√∫n sea el sentimiento (Sentiment), positivo o negativo."
      ],
      "metadata": {
        "id": "IxLd1bkjamrs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se crean subplots de 1 fila, 2 columnas\n",
        "fig, axs = plt.subplots(1, 2, figsize=(18, 6))\n",
        "\n",
        "df['Review_lematizacion'] = df['Review_lematizacion'].apply(lambda x: ' '.join(x) if isinstance(x, list) else x)\n",
        "\n",
        "# Se grafica la nube de palabras con sentimientos positivos\n",
        "df_positivo = df[df['Sentiment'] == 'Positivo']               # Se filtran las filas con sentimiento positivo del DataFrame\n",
        "text_positivo = ' '.join(df_positivo['Review_lematizacion'])  # Se crea una nueva wordcloud con el texto lematizado\n",
        "wordcloud_positivo = WordCloud(width=800, height=400, background_color='white',stopwords=stop_words).generate(text_positivo)\n",
        "axs[0].imshow(wordcloud_positivo, interpolation='bilinear')\n",
        "axs[0].set_title('Nube de Palabras - Texto Positivo')\n",
        "for spine in axs[0].spines.values():\n",
        "    spine.set_edgecolor('gray')\n",
        "    spine.set_linewidth(2)\n",
        "\n",
        "# Se grafica la nube de palabras con sentimientos negativos\n",
        "df_negativo = df[df['Sentiment'] == 'Negativo']               # Se filtran las filas con sentimiento negativo del DataFrame\n",
        "text_negativo = ' '.join(df_negativo['Review_lematizacion'])  # Se crea una nueva wordcloud con el texto lematizado\n",
        "wordcloud_negativo = WordCloud(width=800, height=400, background_color='white',stopwords=stop_words).generate(text_negativo)\n",
        "axs[1].imshow(wordcloud_negativo, interpolation='bilinear')\n",
        "axs[1].set_title('Nube de Palabras - Texto Negativo')\n",
        "#axs[1].axis('off')\n",
        "for spine in axs[1].spines.values():\n",
        "    spine.set_edgecolor('gray')\n",
        "    spine.set_linewidth(2)\n",
        "\n",
        "plt.subplots_adjust(wspace=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "USpppQaYawZb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BAG OF WORDS (BOW)**\n",
        "\n",
        "A continuaci√≥n se crean nubes de palabras en contexto positivo y negativo con n-gramas para captar contexto y matices que no se ver√≠an con palabras individuales.\n",
        "\n",
        "Para esto se utiliza una instancia de CountVectorizer (que convierte una colecci√≥n de textos en una matriz de recuentos de t√©rminos) y luego ajustamos esta instancia (mediante fit_transform) al texto de cada rese√±a. Esto construye el vocabulario y transforma las rese√±as en una matriz BoW (freqs)."
      ],
      "metadata": {
        "id": "Qi5XcMiZxL6y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Review_lematizacion'] = df['Review_lematizacion'].apply(lambda x: ' '.join(x) if isinstance(x, list) else x)  #Para convertir listas en strings si es necesario\n",
        "\n",
        "# Funci√≥n para generar n-gramas\n",
        "def generate_ngrams(texts, n=3):\n",
        "    vectorizer = CountVectorizer(ngram_range=(n, n), stop_words=stop_words)           # Se crea el CountVectorizer con las stop_words definidas\n",
        "    X = vectorizer.fit_transform(texts)                                               # Se transforma el texto en n-gramas\n",
        "    freqs = dict(zip(vectorizer.get_feature_names_out(), X.sum(axis=0).tolist()[0]))  # Se crea el diccionario con los n-gramas y sus frecuencias\n",
        "    return freqs                                                                      # Se devuelve la matriz BOW (el diccionario con los n-gramas y sus frecuencias)\n",
        "\n",
        "# Crear subplots\n",
        "fig, axs = plt.subplots(1, 2, figsize=(18, 6))\n",
        "\n",
        "# Nube de n-gramas para textos positivos\n",
        "ngrams_positivo = generate_ngrams(df[df['Sentiment'] == 'Positivo']['Review_lematizacion'], n=3)\n",
        "wordcloud_positivo = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(ngrams_positivo)\n",
        "axs[0].imshow(wordcloud_positivo, interpolation='bilinear')\n",
        "axs[0].set_title('Nube de n-gramas - Texto Positivo')\n",
        "\n",
        "# Nube de n-gramas para textos negativos\n",
        "ngrams_negativo = generate_ngrams(df[df['Sentiment'] == 'Negativo']['Review_lematizacion'], n=3)\n",
        "wordcloud_negativo = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(ngrams_negativo)\n",
        "axs[1].imshow(wordcloud_negativo, interpolation='bilinear')\n",
        "axs[1].set_title('Nube de n-gramas - Texto Negativo')\n",
        "\n",
        "# Est√©tica\n",
        "for ax in axs:\n",
        "    for spine in ax.spines.values():\n",
        "        spine.set_edgecolor('gray')\n",
        "        spine.set_linewidth(2)\n",
        "\n",
        "plt.subplots_adjust(wspace=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "atMqfKWvuWr_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üí° Las rese√±as positivas est√°n centradas en experiencias satisfactorias y elogios. No obstante, y como era de esperar, en las rese√±as negativas hay una clara expresi√≥n de decepci√≥n (\"really wanted like\", \"sadly going back\") y se perciben problemas de expectativa vs. realidad (\"look nothing like\", \"made look like\")."
      ],
      "metadata": {
        "id": "4a_4RBIhx2hy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **‚óºÔ∏è AN√ÅLISIS DE SENTIMIENTOS**\n",
        "----\n",
        "\n",
        "Se evaluan las rese√±as en cuanto a su polaridad y su subjetividad:\n",
        "* La polaridad mide cu√°n positivo o negativo es el texto, en un rango de -1 (muy negativo) a 1 (muy positivo).\n",
        "* La subjetividad mide cu√°nto del texto es opini√≥n (1) versus hecho (0)."
      ],
      "metadata": {
        "id": "cJcpNQ3wKgGs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se crea una columna con objetos TextBlob sobre la que se har√° el an√°lisis de sentimiento\n",
        "df['Blob'] = df['Review Text'].apply(TextBlob)\n",
        "\n",
        "# Se extraen la polaridad y subjetividad del sentimiento\n",
        "df['Sentiment_Polarity'] = df['Blob'].apply(lambda blob: blob.sentiment.polarity)\n",
        "df['Sentiment_Subjectivity'] = df['Blob'].apply(lambda blob: blob.sentiment.subjectivity)\n",
        "df[['Review Text', 'Sentiment_Polarity', 'Sentiment_Subjectivity']].head(10)"
      ],
      "metadata": {
        "id": "8l11PXYIhf0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_stats = df.groupby('Sentiment')[['Sentiment_Polarity', 'Sentiment_Subjectivity']].mean()  # Se agrupa por sentimiento y calculan promedios\n",
        "\n",
        "print(\"Promedio de polaridad y subjetividad por tipo de sentimiento:\")\n",
        "print(sentiment_stats)"
      ],
      "metadata": {
        "id": "jtgGUnn7l2At"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üí° Los textos clasificados como positivos tienen una **polaridad** levemente mayor que los negativos. No obstante, los textos negativos no son extremadamente negativos (0.108), lo que podr√≠a indicar que las rese√±as negativas, aunque cr√≠ticas, no necesariamente usan lenguaje extremadamente negativo\n",
        "\n",
        "Ambos tipos de rese√±as tienen niveles similares de **subjetividad**, aunque las positivas son ligeramente m√°s subjetivas. Esto sugiere que los usuarios tienden a expresar m√°s emociones o juicios personales cuando est√°n satisfechos."
      ],
      "metadata": {
        "id": "yGmV3tT8p57z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"1\"></a>\n",
        "# <div style=\"padding:20px;color:yellow;margin:0;font-size:30px;font-family:Verdana;text-align:center;display:fill;border-radius:5px;background-color:#333333;overflow:hidden\"><b>MODELADO </b></div>"
      ],
      "metadata": {
        "id": "BqnZsIruleJ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **‚óºÔ∏è TF-IDF - Term Frequency-Inverse Document Frequency**\n",
        "----\n",
        "\n",
        "Para entender qu√© palabras tienen mayor peso dentro de las rese√±as, se aplic√≥ la t√©cnica TF-IDF. Esta herramienta permite identificar qu√© t√©rminos son m√°s representativos en los textos, destacando aquellos que aparecen con frecuencia en una rese√±a pero no en todas.\n",
        "\n",
        "En este trabajo, se utiliz√≥ el vectorizador TF-IDF para transformar los textos en vectores num√©ricos, lo que facilita su an√°lisis y comparaci√≥n. Se aplic√≥ por separado a los textos con sentimiento positivo y negativo, lo que permiti√≥ observar qu√© palabras son m√°s relevantes en cada grupo. Este enfoque ayuda a detectar patrones ling√º√≠sticos asociados a cada tipo de experiencia del usuario."
      ],
      "metadata": {
        "id": "7bloF9ja59bC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuaci√≥n se realiza un **modelo de clasificaci√≥n** para predecir la valoraci√≥n (positiva o negativa) de un cliente a partir de una rese√±a, usando **TF-IDF** para transformar el texto y **Regresi√≥n Log√≠stica** como algoritmo de aprendizaje.\n",
        "\n",
        "Se considera la variable \"Review Text\" como variable independiente sobre la cual se har√°n las predicciones del \"Rating\"."
      ],
      "metadata": {
        "id": "1o6_uYvNdYnU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Entrenamiento del Modelo con el dataset original**\n",
        "\n",
        "Se toma el set de datos original con Ratings del 1 al 5 (multiclase)."
      ],
      "metadata": {
        "id": "Q9ndrTmPoqr1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(dfReviews['Review Text'], dfReviews['Rating'], test_size=0.2, random_state=42)  # Se dividen los datos en conjuntos de entrenamiento y prueba\n",
        "\n",
        "# Vectorizaci√≥n TF-IDF\n",
        "vectorizador_tfidf = TfidfVectorizer(max_features=5000)     # Se crea un vectorizador TF-IDF (el objeto del modelo o herramienta a usar)\n",
        "X_train_tfidf = vectorizador_tfidf.fit_transform(X_train)   # Se ajustan los datos de entrenamiento\n",
        "X_test_tfidf = vectorizador_tfidf.transform(X_test)         # Se transforman los datos de prueba\n",
        "\n",
        "# Escalado de los datos (para mejorar la estabilidad del entrenamiento)\n",
        "#scaler = StandardScaler(with_mean=False)\n",
        "#X_train_scaled = scaler.fit_transform(X_train_tfidf)\n",
        "#X_test_scaled = scaler.transform(X_test_tfidf)\n",
        "\n",
        "# Modelo de regresi√≥n log√≠stica\n",
        "model = LogisticRegression(max_iter=1000)                 # Se instancia el modelo\n",
        "model.fit(X_train_tfidf, y_train)                         # Se entrena el modelo (aprende) a partir de los datos de entrenamiento\n",
        "y_pred = model.predict(X_test_tfidf)                      # Se hacen  predicciones en el conjunto de prueba\n",
        "#y_pred = model.predict(X_test_scaled)                     # Se hacen  predicciones en el conjunto de prueba escalado\n",
        "\n",
        "# Mostrar predicciones\n",
        "print(\"Predicciones del modelo sobre el conjunto de prueba:\")\n",
        "print(y_pred)"
      ],
      "metadata": {
        "id": "7uwHmFmRhCXb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluaci√≥n del Modelo**\n",
        "\n",
        "A continuaci√≥n se eval√∫a el modelo a partir distintas m√©tricas:\n",
        "\n",
        "* **Accuracy:** Indica qu√© tan bien predice el modelo en datos nuevos (exactitud). Mide el porcentaje total de predicciones correctas sobre el total de casos. Es una medida global del desempe√±o.\n",
        "* **Precision:** Indica qu√© proporci√≥n de las predicciones positivas realizadas por el modelo son realmente positivas. Cu√°ntos falsos positivos se est√° evitando.\n",
        "* **Recall:** Indica cu√°ntos de los casos positivos reales fueron capturados por el modelo. Cu√°ntos verdaderos positivos se est√° capturando.\n",
        "* **f1 Score:** Calcula el promedio arm√≥nico entre precisi√≥n y recall. Un buen balance si ambas cosas son importantes. Es √∫til cuando hay cierto desequilibrio entre clases.\n",
        "* **ROC AUC SCORE:** eval√∫a qu√© tan bien el modelo separa las clases. Un valor cercano a 1 indica una excelente discriminaci√≥n entre \"positivo\" y \"negativo\".\n"
      ],
      "metadata": {
        "id": "PML9Pb84ot9q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se calculan las m√©tricas del Modelo\n",
        "accuracy_tfidf_M = accuracy_score(y_test, y_pred)\n",
        "precision_tfidf_M = precision_score(y_test, y_pred, average='weighted')  # Calcula la m√©trica multiclase con average='weighted'\n",
        "recall_tfidf_M = recall_score(y_test, y_pred, average='weighted') # Calcula la m√©trica multiclase con average='weighted'\n",
        "f1_tfidf_M = f1_score(y_test, y_pred, average='weighted') # Calcula la m√©trica multiclase con average='weighted'\n",
        "y_proba_tfidf_M = model.predict_proba(X_test_tfidf)\n",
        "#y_proba_tfidf_M = model.predict_proba(X_test_scaled)\n",
        "roc_auc_tfidf_M = roc_auc_score(y_test, y_proba_tfidf_M, multi_class='ovr', average='weighted') # Calcula la m√©trica multiclase con average='weighted'\n",
        "\n",
        "\n",
        "# Se crea un diccionario para almacenar todas las m√©tricas\n",
        "metricas_modelos = {}\n",
        "\n",
        "# Almaceno las m√©tricas del modelo\n",
        "metricas_modelos['RL_TFIDF_Multiclase'] = {\n",
        "    'Accuracy': accuracy_tfidf_M,\n",
        "    'Precision': precision_tfidf_M,\n",
        "    'Recall': recall_tfidf_M,\n",
        "    'F1 Score': f1_tfidf_M,\n",
        "    'ROC AUC': roc_auc_tfidf_M\n",
        "}\n",
        "\n",
        "print(\"M√©tricas del Modelo con TF-IDF multiclase\")\n",
        "print(f\"- Accuracy: {accuracy_tfidf_M:.3f}\")\n",
        "print(f\"- Precisi√≥n: {precision_tfidf_M:.3f}\")\n",
        "print(f\"- Recall: {recall_tfidf_M:.3f}\")\n",
        "print(f\"- F1 Score: {f1_tfidf_M:.3f}\")\n",
        "print(f\"- ROC AUC Score: {roc_auc_tfidf_M:.3f}\")\n",
        "\n",
        "# Reporte por clase\n",
        "print(\"\\n\\nReporte de Clasificaci√≥n por Clase:\\n\")\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "PGZcsIl2okPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üí° De las m√©tricas obtenidas podemos decir que:\n",
        "* El modelo clasifica correctamente el 65.1% de los casos, lo cual indica un rendimiento aceptable considerando que se trata de una clasificaci√≥n multiclase (ratings del 1 al 5).\n",
        "* En promedio, cuando el modelo predice una clase, acierta el 60.8% de las veces. Esto sugiere que hay cierto nivel de confusi√≥n entre clases, quiz√°s en las m√°s cercanas (por ejemplo, entre 3 y 4).\n",
        "* El modelo logra recuperar el 65.1% de los casos reales, lo que indica que est√° dejando algunos casos sin detectar.\n",
        "* El equilibrio entre precisi√≥n y recall es razonable, aunque hay margen para mejorar la consistencia del modelo.\n",
        "* El ROC AUC Score es relativamente alto, lo que indica que el modelo tiene buena capacidad para distinguir entre clases, especialmente entre las m√°s extremas (ratings bajos vs. altos)."
      ],
      "metadata": {
        "id": "7UIxDT8osSVs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel('Predicci√≥n')\n",
        "plt.ylabel('Valor Real')\n",
        "plt.title('Matriz de Confusi√≥n')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "a6ostPUpphCx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üí° La Matriz de Confusi√≥n indica que:\n",
        "* La clase 5 (rating m√°s alto) tiene la mayor cantidad de aciertos (2313), lo que sugiere que el modelo identifica bien las rese√±as muy positivas.\n",
        "* La clase 3 muestra una dispersi√≥n significativa, con muchos casos clasificados como 4 (561), lo que indica que el modelo tiene dificultades para distinguir entre rese√±as neutras y ligeramente positivas.\n",
        "* Las clases 1 y 2 tienen menos aciertos y m√°s confusi√≥n entre s√≠ y con clases superiores, lo que podr√≠a deberse a menor cantidad de ejemplos o menor diferenciaci√≥n ling√º√≠stica."
      ],
      "metadata": {
        "id": "vdkhC0vZt4N-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Entrenamiento del Modelo con el dataset de clasificaci√≥n binaria (positiva/negativa)**"
      ],
      "metadata": {
        "id": "CksmIbIj2I81"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['SentimentValue'] = np.where(df['Sentiment'] == \"Positivo\", 1, 0)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['Review Text'], df['SentimentValue'], test_size=0.2, random_state=42)  # Se dividen los datos en conjuntos de entrenamiento y prueba\n",
        "\n",
        "# Vectorizaci√≥n TF-IDF\n",
        "vectorizador_tfidf = TfidfVectorizer(max_features=5000)     # Se crea un vectorizador TF-IDF (el objeto del modelo o herramienta a usar)\n",
        "X_train_tfidf = vectorizador_tfidf.fit_transform(X_train)   # Se ajustan los datos de entrenamiento\n",
        "X_test_tfidf = vectorizador_tfidf.transform(X_test)         # Se transforman los datos de prueba\n",
        "\n",
        "# Escalado de los datos (para mejorar la estabilidad del entrenamiento)\n",
        "#scaler = StandardScaler(with_mean=False)\n",
        "#X_train_scaled = scaler.fit_transform(X_train_tfidf)\n",
        "#X_test_scaled = scaler.transform(X_test_tfidf)\n",
        "\n",
        "# Modelo de regresi√≥n log√≠stica\n",
        "model = LogisticRegression(max_iter=1000)                 # Se instancia el modelo\n",
        "model.fit(X_train_tfidf, y_train)                         # Se entrena el modelo (aprende) a partir de los datos de entrenamiento\n",
        "y_pred = model.predict(X_test_tfidf)                      # Se hacen  predicciones en el conjunto de prueba\n",
        "#y_pred = model.predict(X_test_scaled)                     # Se hacen  predicciones en el conjunto de prueba escalado\n",
        "\n",
        "# Mostrar predicciones\n",
        "print(\"Predicciones del modelo sobre el conjunto de prueba:\")\n",
        "print(y_pred)"
      ],
      "metadata": {
        "id": "QegeZvzn0Sr4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluaci√≥n del Modelo**"
      ],
      "metadata": {
        "id": "hPdNl89V2lMy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se calculan las m√©tricas del Modelo\n",
        "accuracy_tfidf_B = accuracy_score(y_test, y_pred)\n",
        "precision_tfidf_B = precision_score(y_test, y_pred)\n",
        "recall_tfidf_B = recall_score(y_test, y_pred)\n",
        "f1_tfidf_B = f1_score(y_test, y_pred)\n",
        "y_proba_tfidf_B = model.predict_proba(X_test_tfidf)[:, 1]   # Probabilidades para la clase positiva\n",
        "#y_proba_tfidf_B = model.predict_proba(X_test_tfidf)\n",
        "#y_proba_tfidf_B = model.predict_proba(X_test_scaled)\n",
        "roc_auc_tfidf_B = roc_auc_score(y_test, y_proba_tfidf_B)\n",
        "\n",
        "# Almaceno las m√©tricas del modelo\n",
        "metricas_modelos['RL_TFIDF_Binario'] = {\n",
        "    'Accuracy': accuracy_tfidf_B,\n",
        "    'Precision': precision_tfidf_B,\n",
        "    'Recall': recall_tfidf_B,\n",
        "    'F1 Score': f1_tfidf_B,\n",
        "    'ROC AUC': roc_auc_tfidf_B\n",
        "}\n",
        "\n",
        "print(\"M√©tricas del Modelo con TF-IDF binario\")\n",
        "print(f\"- Accuracy: {accuracy_tfidf_B:.3f}\")\n",
        "print(f\"- Precisi√≥n: {precision_tfidf_B:.3f}\")\n",
        "print(f\"- Recall: {recall_tfidf_B:.3f}\")\n",
        "print(f\"- F1 Score: {f1_tfidf_B:.3f}\")\n",
        "print(f\"- ROC AUC Score: {roc_auc_tfidf_B:.3f}\")\n",
        "\n",
        "# Reporte por clase\n",
        "print(\"\\n\\nReporte de Clasificaci√≥n por Clase:\\n\")\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "bSsL1UMf2lee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üí° Como era de esperar, las m√©tricas mejoran considerablemente:\n",
        "* El modelo clasifica correctamente el 92.4% de los casos, lo cual indica un rendimiento superior.\n",
        "* En promedio, cuando el modelo predice una clase, acierta el 93.1% de las veces (dado que no se contempla la clase 3-neutral).\n",
        "* El modelo logra recuperar el 98.7% de los casos reales, lo que indica que casi no deja casos sin detectar.\n",
        "* El equilibrio entre precisi√≥n y recall √≥ptimo.\n",
        "* El ROC AUC Score es alto, lo que indica que el modelo tiene buena capacidad para distinguir entre clases."
      ],
      "metadata": {
        "id": "yUQbjkoA6FNY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel('Predicci√≥n')\n",
        "plt.ylabel('Valor Real')\n",
        "plt.title('Matriz de Confusi√≥n')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6iP7wpwM65Be"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üí° Luego, el modelo tiene muy buen desempe√±o para la clase 1, con una alta cantidad de aciertos (3442) y pocos errores (44). Aunque para la clase 0 el rendimiento es m√°s bajo: hay m√°s errores (256) que aciertos (222), lo que indica que el modelo tiende a sobrepredecir la clase 1. Esto podr√≠a deberse a un desequilibrio en los datos, dado que la clase 1 es mucho m√°s frecuente que la clase 0."
      ],
      "metadata": {
        "id": "xPZkeFmr7XyY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **‚óºÔ∏è BOW - BAG OF WORDS**\n",
        "----\n",
        "\n",
        "Para abordar el problema de clasificaci√≥n de rese√±as seg√∫n su calificaci√≥n, se implement√≥ un modelo de **Regresi√≥n Log√≠stica** utilizando la t√©cnica **Bag Of Words (BoW)**. Este enfoque permite transformar el texto en una representaci√≥n num√©rica basada en la frecuencia de aparici√≥n de cada palabra, sin considerar su orden ni contexto.\n",
        "\n",
        "Una vez vectorizados los textos, se entren√≥ el modelo para predecir la variable Rating, permitiendo identificar patrones ling√º√≠sticos asociados a distintas valoraciones.\n",
        "\n",
        "Este modelo sirve como punto de partida para evaluar c√≥mo el contenido textual de las rese√±as se relaciona con la percepci√≥n del usuario, y qu√© tan bien puede predecirse esa percepci√≥n a partir del lenguaje utilizado."
      ],
      "metadata": {
        "id": "A0FFT9dZ77Yb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Entrenamiento del Modelo con el dataset original**\n",
        "\n",
        "Se toma el set de datos original con Ratings del 1 al 5 (multiclase)."
      ],
      "metadata": {
        "id": "B4--XuIqCtLU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se separan la variable dependiente (Review Text) y objetivo (Rating)\n",
        "X = dfReviews['Review Text']\n",
        "y = dfReviews['Rating']\n",
        "\n",
        "# Se divide el dataset en conjunto de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "vectorizador_bow = CountVectorizer()                    # Se inicializa el CountVectorizer (BoW)\n",
        "X_train_bow = vectorizador_bow.fit_transform(X_train)   # Se ajustan las rese√±as de entrenamiento\n",
        "\n",
        "X_train_bow"
      ],
      "metadata": {
        "id": "4e4VwJpECO5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_bow = vectorizador_bow.transform(X_test)         # Se transforman las rese√±as de prueba\n",
        "\n",
        "print(\"Vocabulario BoW:\", vectorizador_bow.get_feature_names_out())\n",
        "print(\"Matriz BoW de entrenamiento:\\n\", X_train_bow.toarray())"
      ],
      "metadata": {
        "id": "K7nIL-YRCUXY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se entrena el modelo de Regresi√≥n Log√≠stica con Bag of Words\n",
        "modelo_bow = LogisticRegression(max_iter=1000)\n",
        "modelo_bow.fit(X_train_bow, y_train)"
      ],
      "metadata": {
        "id": "WUX3d509CWpz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se hacen predicciones en el conjunto de prueba\n",
        "y_pred_bow = modelo_bow.predict(X_test_bow)"
      ],
      "metadata": {
        "id": "E3mMLT96CZSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se calculan las m√©tricas del modelo\n",
        "accuracy_bow_M = accuracy_score(y_test, y_pred_bow)\n",
        "precision_bow_M = precision_score(y_test, y_pred_bow, average='weighted')   # Calcula la m√©trica multiclase con average='weighted'\n",
        "recall_bow_M = recall_score(y_test, y_pred_bow, average='weighted')         # Calcula la m√©trica multiclase con average='weighted'\n",
        "f1_bow_M = f1_score(y_test, y_pred_bow, average='weighted')                 # Calcula la m√©trica multiclase con average='weighted'\n",
        "#y_proba_M = modelo_bow.predict_proba(X_test_tfidf)[:, 1]                    # Probabilidades para la clase positiva\n",
        "#y_proba_M = modelo_bow.predict_proba(X_test_scaled)\n",
        "y_proba_bow_M = modelo_bow.predict_proba(X_test_bow)\n",
        "roc_auc_bow_M = roc_auc_score(y_test, y_proba_bow_M, multi_class='ovr', average='weighted') # Calcula la m√©trica multiclase con average='weighted'\n",
        "\n",
        "# Almaceno las m√©tricas del modelo\n",
        "metricas_modelos['RL_BOW_Multiclase'] = {\n",
        "    'Accuracy': accuracy_bow_M,\n",
        "    'Precision': precision_bow_M,\n",
        "    'Recall': recall_bow_M,\n",
        "    'F1 Score': f1_bow_M,\n",
        "    'ROC AUC': roc_auc_bow_M\n",
        "}\n",
        "\n",
        "print(\"M√©tricas del Modelo con Bag of Words (BoW) multiclase\")\n",
        "print(f\"- Accuracy: {accuracy_bow_M:.3f}\")\n",
        "print(f\"- Precisi√≥n: {precision_bow_M:.3f}\")\n",
        "print(f\"- Recall: {recall_bow_M:.3f}\")\n",
        "print(f\"- F1 Score: {f1_bow_M:.3f}\")\n",
        "print(f\"- ROC AUC Score: {roc_auc_bow_M:.3f}\")\n",
        "\n",
        "# Reporte por clase\n",
        "print(\"\\n\\nReporte de Clasificaci√≥n por Clase:\\n\")\n",
        "print(classification_report(y_test, y_pred_bow))"
      ],
      "metadata": {
        "id": "mcBuXgEcC9b5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Clases en y:\", y.unique())"
      ],
      "metadata": {
        "id": "7EH3bZ6mCPFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Matriz de confusi√≥n\n",
        "cm = confusion_matrix(y_test, y_pred_bow)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel('Predicci√≥n')\n",
        "plt.ylabel('Real')\n",
        "plt.title('Matriz de Confusi√≥n')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7_T1Er3dyhqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Entrenamiento del Modelo con el dataset de clasificaci√≥n binaria (positiva/negativa)**"
      ],
      "metadata": {
        "id": "EPaMDtdPC1Qg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se separan la variable dependiente (Review Text) y objetivo (Rating)\n",
        "X = df['Review Text']\n",
        "y = df['SentimentValue']\n",
        "\n",
        "# Se divide el dataset en conjunto de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "vectorizador_bow = CountVectorizer()                    # Se inicializa el CountVectorizer (BoW)\n",
        "X_train_bow = vectorizador_bow.fit_transform(X_train)   # Se ajustan las rese√±as de entrenamiento\n",
        "\n",
        "X_train_bow"
      ],
      "metadata": {
        "id": "cDQKMuis9Bg6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_bow = vectorizador_bow.transform(X_test)         # Se transforman las rese√±as de prueba\n",
        "\n",
        "print(\"Vocabulario BoW:\", vectorizador_bow.get_feature_names_out())\n",
        "print(\"Matriz BoW de entrenamiento:\\n\", X_train_bow.toarray())"
      ],
      "metadata": {
        "id": "CCE4wo589NHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se entrena el modelo de Regresi√≥n Log√≠stica con Bag of Words\n",
        "modelo_bow = LogisticRegression(max_iter=1000)\n",
        "modelo_bow.fit(X_train_bow, y_train)"
      ],
      "metadata": {
        "id": "1JaEVkJw9Xe-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se hacen predicciones en el conjunto de prueba\n",
        "y_pred_bow = modelo_bow.predict(X_test_bow)"
      ],
      "metadata": {
        "id": "da0ASIuY9d60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se calculan las m√©tricas del modelo\n",
        "accuracy_bow_B = accuracy_score(y_test, y_pred_bow)\n",
        "precision_bow_B = precision_score(y_test, y_pred_bow)\n",
        "recall_bow_B = recall_score(y_test, y_pred_bow)\n",
        "f1_bow_B = f1_score(y_test, y_pred_bow)\n",
        "y_proba_bow_B = modelo_bow.predict_proba(X_test_bow)\n",
        "roc_auc_bow_B = roc_auc_score(y_test, y_proba_bow_B[:, 1])   # Para calcular el ROC AUC en binaria, se usa solo la probabilidad de la clase positiva (1)\n",
        "\n",
        "# Almaceno las m√©tricas del modelo\n",
        "metricas_modelos['RL_BOW_Binario'] = {\n",
        "    'Accuracy': accuracy_bow_B,\n",
        "    'Precision': precision_bow_B,\n",
        "    'Recall': recall_bow_B,\n",
        "    'F1 Score': f1_bow_B,\n",
        "    'ROC AUC': roc_auc_bow_B\n",
        "}\n",
        "\n",
        "print(\"M√©tricas del Modelo con Bag of Words (BoW) en binaria:\")\n",
        "print(f\"- Accuracy: {accuracy_bow_B:.3f}\")\n",
        "print(f\"- Precisi√≥n: {precision_bow_B:.3f}\")\n",
        "print(f\"- Recall: {recall_bow_B:.3f}\")\n",
        "print(f\"- F1 Score: {f1_bow_B:.3f}\")\n",
        "print(f\"- ROC AUC Score: {roc_auc_bow_B:.3f}\")\n",
        "\n",
        "# Reporte por clase\n",
        "print(\"\\n\\nReporte de Clasificaci√≥n por Clase:\\n\")\n",
        "print(classification_report(y_test, y_pred_bow))"
      ],
      "metadata": {
        "id": "xnQxei8BwWF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Matriz de confusi√≥n\n",
        "cm = confusion_matrix(y_test, y_pred_bow)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel('Predicci√≥n')\n",
        "plt.ylabel('Real')\n",
        "plt.title('Matriz de Confusi√≥n')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "xVc62v8qwg_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **‚óºÔ∏è COMPARACI√ìN DE LOS MODELOS**\n",
        "----\n"
      ],
      "metadata": {
        "id": "rRa2MQXQAtYv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_comparacion = pd.DataFrame(metricas_modelos).T  # Transponer para que los modelos sean filas\n",
        "print(df_comparacion.round(3))"
      ],
      "metadata": {
        "id": "QLP3gSmuwh3E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelo TF-IDF\n",
        "\n",
        "df['SentimentValue'] = np.where(df['Sentiment'] == \"Positivo\", 1, 0)\n",
        "\n",
        "# Se dividen los datos en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['Review Text'], df['SentimentValue'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Se divide el dataset en conjunto de entrenamiento y prueba\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "vectorizador_tfidf = TfidfVectorizer(max_features=5000)       # Inicializaci√≥n del vectorizador TF-IDF\n",
        "X_train_tfidf = vectorizador_tfidf.fit_transform(X_train)     # Se ajustan y transforman las rese√±as de entrenamiento\n",
        "#X_test_tfidf = vectorizador_tfidf.transform(X_test)           # Se transforman las rese√±as de prueba\n",
        "modelo_tfidf = LogisticRegression(max_iter=1000)              # Se instancia el modelo\n",
        "modelo_tfidf.fit(X_train_tfidf, y_train)                      # Se entrena el modelo (aprende) a partir de los datos de entrenamiento\n",
        "y_pred_tfidf = modelo_tfidf.predict(X_test_tfidf)             # Se hacen  predicciones en el conjunto de prueba"
      ],
      "metadata": {
        "id": "m0EDYjAv9l2b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelo BOW\n",
        "\n",
        "# Se separan la variable dependiente (Review Text) y objetivo (SentimentValue)\n",
        "X = df['Review Text']\n",
        "y = df['SentimentValue']\n",
        "\n",
        "# Se divide el dataset en conjunto de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "vectorizador_bow = CountVectorizer()                          # Se inicializa el CountVectorizer (BoW)\n",
        "X_train_bow = vectorizador_bow.fit_transform(X_train)         # Se ajustan las rese√±as de entrenamiento\n",
        "modelo_bow = LogisticRegression(max_iter=1000)                # Se instancia el modelo\n",
        "modelo_bow.fit(X_train_bow, y_train)                          # Se entrena el modelo\n",
        "y_pred_bow = modelo_bow.predict(X_test_bow)                   # Se hacen predicciones en el conjunto de prueba"
      ],
      "metadata": {
        "id": "gtobXoX89mX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Funci√≥n para predecir una nueva rese√±a\n",
        "def predecir_rese√±a(nueva_rese√±a, modelo_bow, modelo_tfidf, vectorizador_bow, vectorizador_tfidf):\n",
        "    # Preprocesar la nueva rese√±a\n",
        "    nueva_rese√±a_bow = vectorizador_bow.transform([nueva_rese√±a])\n",
        "    nueva_rese√±a_tfidf = vectorizador_tfidf.transform([nueva_rese√±a])\n",
        "\n",
        "    prediccion_bow = modelo_bow.predict(nueva_rese√±a_bow)           # Predicci√≥n usando Bag of Words\n",
        "    prediccion_tfidf = modelo_tfidf.predict(nueva_rese√±a_tfidf)     # Predicci√≥n usando TF-IDF\n",
        "\n",
        "    # Mostrar resultados\n",
        "    print(f\"Rese√±a ingresada: {nueva_rese√±a}\")\n",
        "    print(f\"Predicci√≥n con Bag of Words: {'Positiva' if prediccion_bow[0] == 1 else 'Negativa'}\")\n",
        "    print(f\"Predicci√≥n con TF-IDF: {'Positiva' if prediccion_tfidf[0] == 1 else 'Negativa'}\")\n",
        "\n",
        "\n",
        "# Simular ingreso de nueva rese√±a por el usuario\n",
        "nueva_rese√±a = input(\"Ingresa una rese√±a de indumentaria: \")\n",
        "predecir_rese√±a(nueva_rese√±a, modelo_bow, modelo_tfidf, vectorizador_bow, vectorizador_tfidf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "AqIjZTVc9t3x",
        "outputId": "90a8e9c6-6368-4763-c6b4-a738fd635a8b"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3806727524.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Simular ingreso de nueva rese√±a por el usuario\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mnueva_rese√±a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Ingresa una rese√±a de indumentaria: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mpredecir_rese√±a\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnueva_rese√±a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodelo_bow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodelo_tfidf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectorizador_bow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectorizador_tfidf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"1\" href=\"#introduccion\"></a>\n",
        "# <div style=\"padding:20px;color:yellow;margin:0;font-size:30px;font-family:Verdana;text-align:center;display:fill;border-radius:5px;background-color:#333333;overflow:hidden\"><b>CONCLUSI√ìN </b></div>"
      ],
      "metadata": {
        "id": "yIT5mKx0Jcl6"
      }
    }
  ]
}